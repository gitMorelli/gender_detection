{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from torchinfo import summary\n",
    "#import torchvision.transforms.functional as F\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights, alexnet, AlexNet_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet18, ResNet18_Weights\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "source_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resnet = transforms.Compose([\n",
    "                    transforms.Resize(256, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Data Augmentation for Contrastive Learning\n",
    "# ------------------------------\n",
    "color_jitter = transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "\n",
    "ContrastiveTransform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([color_jitter], p=0.8),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], \n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# SimCLR data augmentation transform\n",
    "simclr_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),  # kernel_size ~ 0.1 * image size\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPatchDataset(Dataset):\n",
    "    def __init__(self, df,transform=ContrastiveTransform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dirs (list of str): List of directories to load images from.\n",
    "            labels_df (DataFrame): DataFrame containing labeled images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.image_files = df['file_name'].tolist()\n",
    "        self.x1 = df['x'].tolist()\n",
    "        self.y1 = df['y'].tolist()\n",
    "        self.x2 = df['x2'].tolist()\n",
    "        self.y2 = df['y2'].tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        x1=self.x1[idx]\n",
    "        y1=self.y1[idx]\n",
    "        x2=self.x2[idx]\n",
    "        y2=self.y2[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        patch = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        if self.transform:\n",
    "            patch1 = self.transform(patch)\n",
    "            patch2 = self.transform(patch)\n",
    "\n",
    "        return {\n",
    "            'image1': patch1,\n",
    "            'image2': patch2,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveModel(nn.Module):\n",
    "    \"\"\"ResNet Backbone + Projection Head for SimCLR.\"\"\"\n",
    "    def __init__(self, model, projection_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = model\n",
    "        self.encoder.fc = nn.Identity()  # Remove the classification head\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projection_head(features)\n",
    "        return F.normalize(projections, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# NT-Xent Contrastive Loss\n",
    "# ------------------------------\n",
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"Normalized Temperature-scaled Cross Entropy Loss (SimCLR).\"\"\"\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.shape[0]\n",
    "        z = torch.cat([z_i, z_j], dim=0)  # Stack positive pairs\n",
    "        #print(\"stacked: \",z.shape)\n",
    "        #print(z)\n",
    "        similarity_matrix = torch.matmul(z, z.T)  # Cosine similarity\n",
    "        #I don't normalize because the model already does it in the forward pass\n",
    "        #print(\"similarity_matrix: \",similarity_matrix.shape)\n",
    "        #print(similarity_matrix)\n",
    "        \n",
    "        # Remove self-similarity\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(2 * batch_size, -1)\n",
    "        #print(\"similarity_matrix: \",similarity_matrix.shape)\n",
    "        #print(similarity_matrix)\n",
    "        \n",
    "        # Compute positive pairs similarity\n",
    "        '''\n",
    "        positives = torch.cat([torch.diag(similarity_matrix, batch_size-1), \n",
    "                               torch.diag(similarity_matrix, -batch_size+1)], dim=0)\n",
    "        '''\n",
    "        \n",
    "        # Compute NT-Xent loss\n",
    "        #labels = torch.arange(2 * batch_size, device=z.device)\n",
    "        labels = torch.cat([torch.arange(batch_size-1,2*batch_size-1, device=z.device),\n",
    "                            torch.arange(batch_size, device=z.device)], dim=0)\n",
    "        #print(\"labels: \",labels.shape)\n",
    "        #print(labels)\n",
    "        \n",
    "        # Each row should have the highest score at its label index to be used by the crossentropy loss\n",
    "        loss = self.criterion(similarity_matrix / self.temperature, labels)\n",
    "        #labels should be the class indexes. The first argument are the logits.\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Step 1: Contrastive Pretraining\n",
    "# ------------------------------\n",
    "def pretrain_contrastive(model, dataloader, optimizer, device, epochs=10):\n",
    "    model.train()\n",
    "    loss_fn = NTXentLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            x_i, x_j = batch['image1'], batch['image2']\n",
    "            x_i, x_j = x_i.to(device), x_j.to(device)\n",
    "            z_i, z_j = model(x_i), model(x_j)\n",
    "            loss = loss_fn(z_i, z_j)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file=\"icdar_train_df_iam_rimes_patches_20250615_170212.csv\"\n",
    "running = 'new-laptop'\n",
    "saved = 'new-laptop'\n",
    "pretrained = True\n",
    "selected_model='resnet50'\n",
    "train_df = pd.read_csv(f\"{source_path}\\\\outputs\\\\preprocessed_data\\\\{source_file}\")\n",
    "train_df=file_IO.change_filename_from_to(train_df, fr=saved, to=running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model == 'resnet50':\n",
    "    weights = ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = resnet50(weights=weights)\n",
    "else:\n",
    "    raise ValueError(f\"Model {selected_model} is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train\n",
       "0       1          0      0      1\n",
       "1       1          1      0      1\n",
       "2       1          0      1      1\n",
       "3       1          1      1      1\n",
       "4       2          0      0      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the probability of being 0\n",
    "p_train = 0.9\n",
    "N = train_df['index'].nunique()\n",
    "\n",
    "# Create a dataframe with writer column from 1 to 282\n",
    "pages_df = pd.DataFrame({'index': np.arange(1, N+1)})\n",
    "\n",
    "# Add a train column that is randomly 0 or 1 with probability p of being 0\n",
    "pages_df['train'] = np.random.choice([0, 1], size=len(pages_df), p=[1-p_train, p_train])\n",
    "\n",
    "# Merge with the train_df dataframe on the writer column\n",
    "train_df = train_df.merge(pages_df, on='index', how='left')\n",
    "\n",
    "# Display the dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max=N\n",
    "train_dataset = CustomPatchDataset(train_df[(train_df['train']==1) & (train_df['index']<=N_max)] ,transform=ContrastiveTransform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomPatchDataset(train_df[(train_df['train']==0) & (train_df['index']<=N_max)] , transform=ContrastiveTransform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator\n",
    "data_iter = iter(train_dataloader)\n",
    "# Get a single batch\n",
    "batch = next(data_iter)\n",
    "plot_image_batches(batch['image1'], batch['writer'], batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_model = ContrastiveModel(model, projection_dim=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "contrastive_model = contrastive_model.to(device)\n",
    "optimizer = optim.Adam(contrastive_model.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_contrastive(contrastive_model, train_dataloader, optimizer, device, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = os.path.join(source_path, \"outputs\", \"logs\")\n",
    "# Example usage:\n",
    "LOG_OUT_FILE = out_dir+\"\\\\feature_extraction_metadata_log.json\"\n",
    "print(f\"Log file path: {LOG_OUT_FILE}\")\n",
    "file_IO.add_or_update_experiment(\n",
    "    experiment, LOG_OUT_FILE,\n",
    "    custom_metadata={\n",
    "        \"original raw file\": source_data,\n",
    "        \"input file\": input_file_name,\n",
    "        \"FE model\": model_used,\n",
    "        \"FE transform\": transform_used,\n",
    "        \"classifier model\": selected_model,\n",
    "        \"model_params\": feature_extraction_model[selected_model].get_params(),\n",
    "        \"n_splits\": n_splits,\n",
    "        \"train_on_language\": train_on_language,\n",
    "        \"train_on_same\": train_on_same,\n",
    "        \"task\": task,\n",
    "        \"with cross validation\": with_cross_validation,\n",
    "        \"with PCA\": with_pca,\n",
    "        \"training time for cross-validation\": time_taken_cross_val,\n",
    "        \"training time for final model\": time_taken,\n",
    "        \"cross_val_accuracies\": cross_val_accuracies,\n",
    "        \"subgroup_accuracies\": subgroup_accuracies,\n",
    "        \"is_kaggle\": is_kaggle,\n",
    "        \"test\": 'this is a test column',\n",
    "        \"description\": ''' I am training a classifier on the feature vectors extracted by a deep model\n",
    "        I am evaluating the results on subsets of the training data, based on language and same/different text.''' \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch tensor1 shape: torch.Size([3, 3, 256, 256])\n",
      "Batch tensor2 shape: torch.Size([3, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class RandomTensorDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=(256, 256, 3)):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor1 = torch.rand(*self.image_size).permute(2, 0, 1)  # Convert to (C, H, W)\n",
    "        #tensor2 = torch.rand(*self.image_size).permute(2, 0, 1)  # Convert to (C, H, W)\n",
    "        tensor2 = tensor1.clone()\n",
    "        return tensor1, tensor2\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "random_dataset = RandomTensorDataset(num_samples=1000)\n",
    "random_dataloader = DataLoader(random_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# Example: Fetch a batch\n",
    "random_batch = next(iter(random_dataloader))\n",
    "print(f\"Batch tensor1 shape: {random_batch[0].shape}\")\n",
    "print(f\"Batch tensor2 shape: {random_batch[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch representation1 shape: torch.Size([3, 10])\n",
      "Batch representation2 shape: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "x_i,x_j = random_batch[0],random_batch[1]\n",
    "z_i, z_j = contrastive_model(x_i), contrastive_model(x_j)\n",
    "print(f\"Batch representation1 shape: {z_i.shape}\")\n",
    "print(f\"Batch representation2 shape: {z_j.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z_i[0]-z_j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked:  torch.Size([6, 10])\n",
      "tensor([[-0.3102,  0.0861,  0.0577,  0.2929, -0.6085, -0.2531,  0.1815, -0.3245,\n",
      "         -0.1531,  0.4597],\n",
      "        [ 0.1333, -0.0379,  0.1585, -0.1918, -0.4724,  0.0645,  0.3494, -0.3464,\n",
      "         -0.4000,  0.5380],\n",
      "        [-0.2865, -0.0284,  0.3475, -0.2848, -0.5702, -0.1441,  0.1548, -0.4361,\n",
      "         -0.2580,  0.2976],\n",
      "        [-0.3102,  0.0861,  0.0577,  0.2929, -0.6085, -0.2531,  0.1815, -0.3245,\n",
      "         -0.1531,  0.4597],\n",
      "        [ 0.1333, -0.0379,  0.1585, -0.1918, -0.4724,  0.0645,  0.3494, -0.3464,\n",
      "         -0.4000,  0.5380],\n",
      "        [-0.2865, -0.0284,  0.3475, -0.2848, -0.5702, -0.1441,  0.1548, -0.4361,\n",
      "         -0.2580,  0.2976]], grad_fn=<CatBackward0>)\n",
      "similarity_matrix:  torch.Size([6, 6])\n",
      "tensor([[1.0000, 0.6639, 0.7524, 1.0000, 0.6639, 0.7524],\n",
      "        [0.6639, 1.0000, 0.8012, 0.6639, 1.0000, 0.8012],\n",
      "        [0.7524, 0.8012, 1.0000, 0.7524, 0.8012, 1.0000],\n",
      "        [1.0000, 0.6639, 0.7524, 1.0000, 0.6639, 0.7524],\n",
      "        [0.6639, 1.0000, 0.8012, 0.6639, 1.0000, 0.8012],\n",
      "        [0.7524, 0.8012, 1.0000, 0.7524, 0.8012, 1.0000]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "similarity_matrix:  torch.Size([6, 5])\n",
      "tensor([[0.6639, 0.7524, 1.0000, 0.6639, 0.7524],\n",
      "        [0.6639, 0.8012, 0.6639, 1.0000, 0.8012],\n",
      "        [0.7524, 0.8012, 0.7524, 0.8012, 1.0000],\n",
      "        [1.0000, 0.6639, 0.7524, 0.6639, 0.7524],\n",
      "        [0.6639, 1.0000, 0.8012, 0.6639, 0.8012],\n",
      "        [0.7524, 0.8012, 1.0000, 0.7524, 0.8012]], grad_fn=<ViewBackward0>)\n",
      "labels:  torch.Size([6])\n",
      "tensor([2, 3, 4, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = NTXentLoss()\n",
    "loss = loss_fn(z_i, z_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.image_processing as image_processing\n",
    "    import utils.file_IO as file_IO\n",
    "    import utils.visualization as visualization\n",
    "    import utils.tests as tests\n",
    "\n",
    "    importlib.reload(file_IO)\n",
    "    importlib.reload(image_processing)\n",
    "    importlib.reload(visualization)\n",
    "    importlib.reload(tests)\n",
    "\n",
    "    return image_processing, file_IO, visualization, tests\n",
    "image_processing, file_IO, visualization, tests = reload_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_batches(batch1, batch2, n=8, figsize=(16, 4)):\n",
    "    \"\"\"\n",
    "    Plots two batches of images: first row is batch1, second row is batch2.\n",
    "    Args:\n",
    "        batch1 (Tensor): Batch of images (B, C, H, W)\n",
    "        batch2 (Tensor): Batch of images (B, C, H, W)\n",
    "        n (int): Number of images to plot from each batch\n",
    "        figsize (tuple): Figure size\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    n = min(n, batch1.shape[0], batch2.shape[0])\n",
    "    fig, axes = plt.subplots(2, n, figsize=figsize)\n",
    "    for i in range(n):\n",
    "        img1 = batch1[i].cpu()\n",
    "        img2 = batch2[i].cpu()\n",
    "        # Unnormalize if needed (assuming ImageNet stats)\n",
    "        if img1.shape[0] == 3:\n",
    "            img1 = img1 * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "            img2 = img2 * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "            img1 = img1.clamp(0,1)\n",
    "            img2 = img2.clamp(0,1)\n",
    "        axes[0, i].imshow(img1.permute(1, 2, 0).numpy())\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(img2.permute(1, 2, 0).numpy())\n",
    "        axes[1, i].axis('off')\n",
    "    axes[0, 0].set_ylabel('Batch 1', fontsize=14)\n",
    "    axes[1, 0].set_ylabel('Batch 2', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
