{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa895c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "#from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add the root of the project to the path\n",
    "source_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(source_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46770319",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_inputs ={'kaggle': 'icdar_train_df_KAGGLE_20250514_181737.csv','original':'icdar_train_df_20250514_175905.csv', \n",
    "                  'patch_dataset':'icdar_train_df_patches_20250515_164130.csv',\n",
    "                  'smaller_patches':'icdar_train_df_patches_20250521_120324.csv', }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147edcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_from= 'original'  # 'original', 'patch_dataset', 'smaller_patches'\n",
    "if extracted_from not in possible_inputs:\n",
    "    raise ValueError(f\"Invalid input type: {extracted_from}. Choose from {list(possible_inputs.keys())}.\")\n",
    "# i select the model and get all the instances in which I used that model on that data\n",
    "# for each instance i get the transforms related data and return the info on the transforms  \n",
    "model_used = 'trocr-base-handwritten'\n",
    "get_info = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4418053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I select the transform and load the input file corresponding to that model and transform (the most recent one)\n",
    "transform_used = ''\n",
    "input_file_name = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name='icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv'\n",
    "input_file=source_path+'\\\\outputs\\\\preprocessed_data\\\\'+input_file_name\n",
    "train_FE = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6235a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE = file_IO.change_filename_from_to(train_FE, fr=\"old-laptop\", to=\"new-laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e3a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_kaggle = False\n",
    "with_pca=True\n",
    "with_cross_validation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric columns: 523\n",
      "Number of columns with missing values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "check number of \n",
    "# Count numeric columns\n",
    "num_numeric_cols = train_FE.select_dtypes(include=['number']).shape[1]\n",
    "\n",
    "# Count columns with missing values\n",
    "num_missing_cols = train_FE.isnull().any().sum()\n",
    "\n",
    "# Display results\n",
    "print(f'Number of numeric columns: {num_numeric_cols}')\n",
    "print(f'Number of columns with missing values: {num_missing_cols}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78875a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writer', 'isEng', 'same_text', 'file_name', 'male', 'train', 'index', 'x', 'y', 'x2', 'y2', 'n_cc']\n"
     ]
    }
   ],
   "source": [
    "target_label='male'\n",
    "#target_label='isEng'\n",
    "if is_kaggle:\n",
    "    cols_to_drop = ['writer', 'same_text', 'train','page_id','isEng','train','index','male']\n",
    "else:\n",
    "    cols_to_drop = [c for c in train_FE.columns if not(c.startswith('f') and len(c) > 1 and c[1].isdigit())]\n",
    "    print(cols_to_drop)\n",
    "X_train = train_FE[train_FE['train']==1].drop(columns=cols_to_drop)\n",
    "y_train = train_FE[train_FE['train']==1][target_label]\n",
    "X_val = train_FE[train_FE['train']==0].drop(columns=cols_to_drop)\n",
    "y_val = train_FE[train_FE['train']==0][target_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbb24f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "gbm_classifier = GradientBoostingClassifier(\n",
    "    n_estimators=100,  \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=3,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cat = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "feature_extraction_model = {'gbm': gbm_classifier, 'cat': cat, 'lgbm': lgbm, 'xgb': xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2adb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'gbm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e31548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#feature_extraction_model = {'gbm': gbm_classifier, 'cat': cat, 'lgbm': lgbm, 'xgb': xgb}\n",
    "# Define the pipeline\n",
    "if with_pca:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=384)  \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalize features\n",
    "        ('pca', pca),  # Apply PCA\n",
    "        (selected_model, feature_extraction_model[selected_model])  # Train GBM classifier\n",
    "    ])\n",
    "else:    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalize features\n",
    "        (selected_model, feature_extraction_model[selected_model])  # Train GBM classifier\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dccd92ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 674.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken to fit the model: {time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50ebc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6276\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation data\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae16cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Accuracy: 0.8421\n"
     ]
    }
   ],
   "source": [
    "# Predict on train data\n",
    "y_pred = pipeline.predict(X_train)\n",
    "\n",
    "# Evaluate accuracy\n",
    "training_accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f'training Accuracy: {training_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9deb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\models\\deep_feature_extraction_model_male_gbm_val0-63_20250520_173200.joblib\n"
     ]
    }
   ],
   "source": [
    "source_path = \"D:\\\\burtm\\\\Visual_studio_code\\\\PD_related_projects\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = os.path.join(source_path, \"outputs\", \"models\")\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "if is_kaggle:\n",
    "    tipo='kaggle'\n",
    "else:\n",
    "    tipo='deep'\n",
    "# Save the model\n",
    "model_filename = os.path.join(output_dir, f\"{tipo}_feature_extraction_model_{target_label}_{selected_model}_val{str(round(accuracy, 2)).replace('.', '-')}_{timestamp}.joblib\")\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3335e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\models\\file_metadata_log.json\n",
      "Output file path: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\models\\deep_feature_extraction_model_male_gbm_val0-63_20250520_173200.joblib\n",
      "Updated log for deep_feature_extraction_model_male_gbm_val0-63_20250520_173200.joblib\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "LOG_FILE = output_dir+\"\\\\file_metadata_log.json\"\n",
    "print(f\"Log file path: {LOG_FILE}\")\n",
    "print(f\"Output file path: {model_filename}\")\n",
    "file_IO.add_or_update_file(\n",
    "    model_filename, LOG_FILE,\n",
    "    custom_metadata={\n",
    "        #\"seed\": seed,\n",
    "        \"trained on file\": os.path.basename(input_file),\n",
    "        \"model\": selected_model,\n",
    "        \"model_params\": feature_extraction_model[selected_model].get_params(),\n",
    "        \"training time\": time_taken,\n",
    "        \"accuracy train\": training_accuracy,\n",
    "        \"accuracy val\": accuracy,\n",
    "        \"problem type\": target_label,\n",
    "        \"input file\": input_file,\n",
    "        \"with PCA\": with_pca,\n",
    "        \"description\": '''I am testing a drnet50 model with a GBM classifier on the features extracted from the images.''' \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d26dd36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for deep_feature_extraction_model_male_gbm_val0-67_20250517_160824.joblib:\n",
      "full_path: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\models\\deep_feature_extraction_model_male_gbm_val0-67_20250517_160824.joblib\n",
      "size_bytes: 221717\n",
      "created: 2025-05-17T16:08:25.016231\n",
      "modified: 2025-05-17T16:08:25.364292\n",
      "accessed: 2025-05-17T16:08:25.364292\n",
      "trained on file: icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv\n",
      "model: gbm\n",
      "model_params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "training time: 277.32010316848755\n",
      "accuracy train: 0.8478260869565217\n",
      "accuracy val: 0.6655172413793103\n",
      "problem type: male\n",
      "input file: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\preprocessed_data\\icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv\n",
      "description: training information for the model\n"
     ]
    }
   ],
   "source": [
    "file_IO.read_metadata(\n",
    "    model_filename,\n",
    "    log_path=LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7024107",
   "metadata": {},
   "source": [
    "# easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eaf8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.file_IO as file_IO\n",
    "    \n",
    "\n",
    "    importlib.reload(file_IO)\n",
    "\n",
    "    return file_IO\n",
    "\n",
    "file_IO = reload_modules()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
