{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa895c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "#from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add the root of the project to the path\n",
    "source_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(source_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46770319",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_inputs ={'kaggle': 'icdar_train_df_KAGGLE_20250514_181737.csv','original':'icdar_train_df_20250514_175905.csv', \n",
    "                  'patch_dataset':'icdar_train_df_patches_20250515_164130.csv',\n",
    "                  'smaller_patches':'icdar_train_df_patches_20250521_120324.csv', }\n",
    "output_dir = source_path + \"\\\\outputs\\\\preprocessed_data\\\\\"\n",
    "LOG_FILE = output_dir+\"file_metadata_log.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "147edcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv:\n",
      "model: trocr-small-stage1\n",
      "description: I am performing inference with trocr-small-stage1 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-handwritten_20250516_150814.csv:\n",
      "model: trocr-small-handwritten\n",
      "description: I am performing inference with trocr-small-handwritten on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv:\n",
      "model: resnet50\n",
      "custom transform: False\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_163737.csv:\n",
      "model: resnet50\n",
      "custom transform: True\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv:\n",
      "model: vit-base-patch16-224-in21k\n",
      "custom transform: False\n",
      "description: I am performing inference with the vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv:\n",
      "model: trocr-base-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-base model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv:\n",
      "model: clip-vit-large-patch14\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the clip-vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ... I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-large-handwritten_20250517_150651.csv:\n",
      "model: trocr-large-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-large model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ..., f1024 I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for representations_trocr-small-stage1_remove head_20250517_191157.h5:\n",
      "model: trocr-small-stage1\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the trocr-small-stage1 model on the patches dataset and \n",
      "        saving the representations of all the patches in a h5 file. It serves for exploring how to best exploit the\n",
      "        extracted representations (using cls, pooling  ..)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_dresnet50_20250520_143808.csv:\n",
      "model: dresnet50\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the dbresnet model pretrained for scene text detection on the patches dataset the output is a pool of the features \n",
      "        of the deepest feature map (the model returns multiple features map since it is a feature pyramid network)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_153435.csv:\n",
      "model: crnn_vgg16_bn\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        PROBLEM: the preprocessing from nxn to 32x128 makes the image look very bad -> i should try other preprocessing approaches\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_161925.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: crop\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to 128x128 and then cropping the central region 32x128\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_165111.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: padding\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to H/3 x W and then resizing to 32x128 with padding\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vitstr_base_20250524_001621.csv:\n",
      "model: vitstr_base\n",
      "transform_mode: resize\n",
      "custom transform: False\n",
      "description: \n",
      "        testing the vitstr model with the icdar patch dataset\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "extracted_from= 'patch_dataset'  # 'original', 'patch_dataset', 'smaller_patches'\n",
    "if extracted_from not in possible_inputs:\n",
    "    raise ValueError(f\"Invalid input type: {extracted_from}. Choose from {list(possible_inputs.keys())}.\")\n",
    "else:\n",
    "    source_data = possible_inputs[extracted_from]\n",
    "# i select the model and get all the instances in which I used that model on that data\n",
    "# for each instance i get the transforms related data and return the info on the transforms  \n",
    "file_IO.show_model_instances(LOG_FILE,['model',\"transform_mode\",\"custom transform\",\"description\"], source_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4418053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv\n"
     ]
    }
   ],
   "source": [
    "# I select the transform and load the input file corresponding to that model and transform (the most recent one)\n",
    "model_used = 'clip-vit-large-patch14'\n",
    "transform_used = ''\n",
    "file_IO.get_file_name(LOG_FILE,{'model':model_used},source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cab0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name='icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250604_201425.csv'\n",
    "input_file=source_path+'\\\\outputs\\\\preprocessed_data\\\\'+input_file_name\n",
    "train_FE = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6235a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE = file_IO.change_filename_from_to(train_FE, fr=\"old-laptop\", to=\"new-laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7a16fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_patches(train_df, n_patches=10):\n",
    "    grouped_sorted = train_df.groupby('page', group_keys=False).apply(lambda x: x.sort_values('black_ratio', ascending=False))\n",
    "    grouped_sorted = grouped_sorted.groupby('page', group_keys=False).head(n_patches)\n",
    "    return grouped_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed19b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE['page'] = train_FE.groupby(['writer', 'isEng', 'same_text']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5062d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_34524\\1653312610.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_sorted = train_df.groupby('page', group_keys=False).apply(lambda x: x.sort_values('black_ratio', ascending=False))\n"
     ]
    }
   ],
   "source": [
    "n_patches = 1\n",
    "if n_patches > 0:\n",
    "    #print(f\"Selecting {n_patches} patches per page...\")\n",
    "    train_FE = select_n_patches(train_FE, n_patches=n_patches).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00f2f69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>isEng</th>\n",
       "      <th>same_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>train</th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>...</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>984</td>\n",
       "      <td>1968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063661</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>-0.018130</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>-0.004420</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2214</td>\n",
       "      <td>1968</td>\n",
       "      <td>2460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>-0.024216</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>-0.015528</td>\n",
       "      <td>-0.011971</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1729</td>\n",
       "      <td>741</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026420</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>-0.022242</td>\n",
       "      <td>-0.032118</td>\n",
       "      <td>0.033636</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>-0.008457</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1476</td>\n",
       "      <td>1230</td>\n",
       "      <td>1722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028946</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>-0.019674</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>-0.040938</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>988</td>\n",
       "      <td>494</td>\n",
       "      <td>1235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020056</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>-0.034672</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>-0.011511</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16854</td>\n",
       "      <td>1488</td>\n",
       "      <td>1984</td>\n",
       "      <td>1736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032084</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.024554</td>\n",
       "      <td>-0.008671</td>\n",
       "      <td>0.032149</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.027986</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16865</td>\n",
       "      <td>1976</td>\n",
       "      <td>494</td>\n",
       "      <td>2223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016214</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>-0.036551</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.041912</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>-0.010395</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16880</td>\n",
       "      <td>1729</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.058978</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>-0.017661</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>0.024855</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16890</td>\n",
       "      <td>988</td>\n",
       "      <td>741</td>\n",
       "      <td>1235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067134</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.037255</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>-0.021708</td>\n",
       "      <td>-0.004189</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16906</td>\n",
       "      <td>984</td>\n",
       "      <td>1722</td>\n",
       "      <td>1230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>-0.004924</td>\n",
       "      <td>-0.008429</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      writer  isEng  same_text  \\\n",
       "0          1      0          0   \n",
       "1          1      0          1   \n",
       "2          1      1          0   \n",
       "3          1      1          1   \n",
       "4          2      0          0   \n",
       "...      ...    ...        ...   \n",
       "1123     281      1          1   \n",
       "1124     282      0          0   \n",
       "1125     282      0          1   \n",
       "1126     282      1          0   \n",
       "1127     282      1          1   \n",
       "\n",
       "                                              file_name  male  train  index  \\\n",
       "0     C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1      0   \n",
       "1     C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1     29   \n",
       "2     C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1     43   \n",
       "3     C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1     54   \n",
       "4     C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1     64   \n",
       "...                                                 ...   ...    ...    ...   \n",
       "1123  C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1  16854   \n",
       "1124  C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1  16865   \n",
       "1125  C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1  16880   \n",
       "1126  C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1  16890   \n",
       "1127  C:\\Users\\andre\\PhD\\Datasets\\ICDAR 2013 - Gende...     0      1  16906   \n",
       "\n",
       "         x     y    x2  ...      f760      f761      f762      f763      f764  \\\n",
       "0     1722   984  1968  ... -0.063661 -0.004135  0.008908 -0.031945  0.025556   \n",
       "1     2214  1968  2460  ... -0.010577  0.003800 -0.024216  0.011542  0.044000   \n",
       "2     1729   741  1976  ... -0.026420 -0.002679 -0.022242 -0.032118  0.033636   \n",
       "3     1476  1230  1722  ... -0.028946  0.003766  0.015801 -0.019674 -0.000178   \n",
       "4      988   494  1235  ... -0.020056  0.002735 -0.034672  0.014498  0.035240   \n",
       "...    ...   ...   ...  ...       ...       ...       ...       ...       ...   \n",
       "1123  1488  1984  1736  ... -0.032084  0.011354  0.024554 -0.008671  0.032149   \n",
       "1124  1976   494  2223  ... -0.016214  0.006361 -0.036551  0.007864  0.041912   \n",
       "1125  1729  1976  1976  ... -0.024396  0.003282 -0.028300  0.007869  0.058978   \n",
       "1126   988   741  1235  ... -0.067134 -0.005375 -0.001508  0.009565  0.037255   \n",
       "1127   984  1722  1230  ... -0.001682  0.023492 -0.008138 -0.005111  0.030361   \n",
       "\n",
       "          f765      f766      f767      f768  page  \n",
       "0    -0.018130  0.020174 -0.004420 -0.005928     0  \n",
       "1     0.001486 -0.015528 -0.011971  0.027188     1  \n",
       "2     0.003242 -0.008457  0.004689  0.010835     2  \n",
       "3    -0.005016  0.005835 -0.040938  0.012388     3  \n",
       "4     0.008573 -0.011511 -0.009830  0.020715     4  \n",
       "...        ...       ...       ...       ...   ...  \n",
       "1123  0.000281  0.027986  0.012711  0.000463  1123  \n",
       "1124 -0.001423 -0.010395 -0.007492  0.018502  1124  \n",
       "1125  0.003996 -0.017661 -0.014423  0.024855  1125  \n",
       "1126  0.011904 -0.021708 -0.004189 -0.025094  1126  \n",
       "1127 -0.004310  0.007226 -0.004924 -0.008429  1127  \n",
       "\n",
       "[1128 rows x 782 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc61b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writer', 'isEng', 'same_text', 'file_name', 'male', 'train', 'index', 'x', 'y', 'x2', 'y2', 'n_cc', 'black_ratio', 'page']\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = [c for c in train_FE.columns if not(c.startswith('f') and len(c) > 1 and c[1].isdigit())]\n",
    "print(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62e3a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writer', 'isEng', 'same_text', 'file_name', 'male', 'train', 'index', 'x', 'y', 'x2', 'y2', 'n_cc', 'page']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"X_train = train_FE[train_FE['train']==1].drop(columns=cols_to_drop)\\ny_train = train_FE[train_FE['train']==1][target_label]\\nX_val = train_FE[train_FE['train']==0].drop(columns=cols_to_drop)\\ny_val = train_FE[train_FE['train']==0][target_label]\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_kaggle = False\n",
    "with_pca=True\n",
    "with_cross_validation=True\n",
    "task = 'gender_detection' #, gender detection, language detection, 'writer identification'\n",
    "train_on_language = 'all' #, english, all, arabic\n",
    "train_on_same = 'all' #, different, all, same\n",
    "n_splits=5\n",
    "if task == 'language detection' and train_on_language != 'all':\n",
    "    raise ValueError(\"For language detection, 'train_on' must be 'all'.\")\n",
    "if task=='gender_detection':\n",
    "    target_label='male'\n",
    "else:\n",
    "    target_label='isEng'\n",
    "if is_kaggle:\n",
    "    cols_to_drop = ['writer', 'same_text', 'train','page_id','isEng','train','index','male']\n",
    "else:\n",
    "    cols_to_drop = [c for c in train_FE.columns if not(c.startswith('f') and len(c) > 1 and c[1].isdigit())]\n",
    "    print(cols_to_drop)\n",
    "\n",
    "'''X_train = train_FE[train_FE['train']==1].drop(columns=cols_to_drop)\n",
    "y_train = train_FE[train_FE['train']==1][target_label]\n",
    "X_val = train_FE[train_FE['train']==0].drop(columns=cols_to_drop)\n",
    "y_val = train_FE[train_FE['train']==0][target_label]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed6c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"check number of \\n# Count numeric columns\\nnum_numeric_cols = train_FE.select_dtypes(include=['number']).shape[1]\\n\\n# Count columns with missing values\\nnum_missing_cols = train_FE.isnull().any().sum()\\n\\n# Display results\\nprint(f'Number of numeric columns: {num_numeric_cols}')\\nprint(f'Number of columns with missing values: {num_missing_cols}')\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check number of \n",
    "# Count numeric columns\n",
    "num_numeric_cols = train_FE.select_dtypes(include=['number']).shape[1]\n",
    "\n",
    "# Count columns with missing values\n",
    "num_missing_cols = train_FE.isnull().any().sum()\n",
    "\n",
    "# Display results\n",
    "print(f'Number of numeric columns: {num_numeric_cols}')\n",
    "print(f'Number of columns with missing values: {num_missing_cols}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cef35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: (np.int64(0), np.int64(0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>isEng</th>\n",
       "      <th>same_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>train</th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>...</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275631</td>\n",
       "      <td>0.058159</td>\n",
       "      <td>-0.001750</td>\n",
       "      <td>-0.269634</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.180648</td>\n",
       "      <td>-0.243915</td>\n",
       "      <td>-0.396190</td>\n",
       "      <td>0.520203</td>\n",
       "      <td>-1.462304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "      <td>986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271600</td>\n",
       "      <td>0.066998</td>\n",
       "      <td>0.031707</td>\n",
       "      <td>-0.261003</td>\n",
       "      <td>0.210312</td>\n",
       "      <td>0.202038</td>\n",
       "      <td>-0.280518</td>\n",
       "      <td>-0.420835</td>\n",
       "      <td>0.522806</td>\n",
       "      <td>-1.437481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1479</td>\n",
       "      <td>493</td>\n",
       "      <td>1972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221603</td>\n",
       "      <td>0.073357</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.191817</td>\n",
       "      <td>0.199360</td>\n",
       "      <td>0.190194</td>\n",
       "      <td>-0.270286</td>\n",
       "      <td>-0.385847</td>\n",
       "      <td>0.498827</td>\n",
       "      <td>-1.451828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>986</td>\n",
       "      <td>493</td>\n",
       "      <td>1479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225266</td>\n",
       "      <td>0.062873</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>-0.242814</td>\n",
       "      <td>0.213373</td>\n",
       "      <td>0.197258</td>\n",
       "      <td>-0.285037</td>\n",
       "      <td>-0.393540</td>\n",
       "      <td>0.503814</td>\n",
       "      <td>-1.470287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1972</td>\n",
       "      <td>493</td>\n",
       "      <td>2465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213585</td>\n",
       "      <td>0.063182</td>\n",
       "      <td>-0.015335</td>\n",
       "      <td>-0.204292</td>\n",
       "      <td>0.231909</td>\n",
       "      <td>0.235870</td>\n",
       "      <td>-0.279547</td>\n",
       "      <td>-0.388177</td>\n",
       "      <td>0.468346</td>\n",
       "      <td>-1.508323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  isEng  same_text                 file_name  male  train  index  \\\n",
       "0       1      0          0  unzipped/1_50/0001_1.jpg     0      1      0   \n",
       "1       1      0          0  unzipped/1_50/0001_1.jpg     0      1      1   \n",
       "2       1      0          0  unzipped/1_50/0001_1.jpg     0      1      2   \n",
       "3       1      0          0  unzipped/1_50/0001_1.jpg     0      1      3   \n",
       "4       1      0          0  unzipped/1_50/0001_1.jpg     0      1      4   \n",
       "\n",
       "      x    y    x2  ...      f759      f760      f761      f762      f763  \\\n",
       "0     0  493   493  ... -0.275631  0.058159 -0.001750 -0.269634  0.219695   \n",
       "1   493  493   986  ... -0.271600  0.066998  0.031707 -0.261003  0.210312   \n",
       "2  1479  493  1972  ... -0.221603  0.073357 -0.017823 -0.191817  0.199360   \n",
       "3   986  493  1479  ... -0.225266  0.062873  0.013257 -0.242814  0.213373   \n",
       "4  1972  493  2465  ... -0.213585  0.063182 -0.015335 -0.204292  0.231909   \n",
       "\n",
       "       f764      f765      f766      f767      f768  \n",
       "0  0.180648 -0.243915 -0.396190  0.520203 -1.462304  \n",
       "1  0.202038 -0.280518 -0.420835  0.522806 -1.437481  \n",
       "2  0.190194 -0.270286 -0.385847  0.498827 -1.451828  \n",
       "3  0.197258 -0.285037 -0.393540  0.503814 -1.470287  \n",
       "4  0.235870 -0.279547 -0.388177  0.468346 -1.508323  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: (np.int64(0), np.int64(1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>isEng</th>\n",
       "      <th>same_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>train</th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>...</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>493</td>\n",
       "      <td>1479</td>\n",
       "      <td>986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>0.081438</td>\n",
       "      <td>-0.026993</td>\n",
       "      <td>-0.202966</td>\n",
       "      <td>0.186488</td>\n",
       "      <td>0.202112</td>\n",
       "      <td>-0.260245</td>\n",
       "      <td>-0.378924</td>\n",
       "      <td>0.496770</td>\n",
       "      <td>-1.494687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>1479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288985</td>\n",
       "      <td>0.087640</td>\n",
       "      <td>0.049662</td>\n",
       "      <td>-0.208533</td>\n",
       "      <td>0.235510</td>\n",
       "      <td>0.152196</td>\n",
       "      <td>-0.247914</td>\n",
       "      <td>-0.395293</td>\n",
       "      <td>0.474001</td>\n",
       "      <td>-1.424915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1479</td>\n",
       "      <td>1479</td>\n",
       "      <td>1972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270145</td>\n",
       "      <td>0.070758</td>\n",
       "      <td>-0.028458</td>\n",
       "      <td>-0.210834</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.216413</td>\n",
       "      <td>-0.248142</td>\n",
       "      <td>-0.398217</td>\n",
       "      <td>0.536445</td>\n",
       "      <td>-1.459662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>493</td>\n",
       "      <td>986</td>\n",
       "      <td>986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287041</td>\n",
       "      <td>0.121514</td>\n",
       "      <td>-0.008135</td>\n",
       "      <td>-0.220779</td>\n",
       "      <td>0.179901</td>\n",
       "      <td>0.202289</td>\n",
       "      <td>-0.235622</td>\n",
       "      <td>-0.422261</td>\n",
       "      <td>0.486641</td>\n",
       "      <td>-1.461829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1479</td>\n",
       "      <td>986</td>\n",
       "      <td>1972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254537</td>\n",
       "      <td>0.080850</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>-0.200407</td>\n",
       "      <td>0.215601</td>\n",
       "      <td>0.180609</td>\n",
       "      <td>-0.256348</td>\n",
       "      <td>-0.401637</td>\n",
       "      <td>0.495235</td>\n",
       "      <td>-1.471664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  isEng  same_text                 file_name  male  train  index  \\\n",
       "5       1      0          1  unzipped/1_50/0001_2.jpg     0      1      5   \n",
       "6       1      0          1  unzipped/1_50/0001_2.jpg     0      1      6   \n",
       "7       1      0          1  unzipped/1_50/0001_2.jpg     0      1      7   \n",
       "8       1      0          1  unzipped/1_50/0001_2.jpg     0      1      8   \n",
       "9       1      0          1  unzipped/1_50/0001_2.jpg     0      1      9   \n",
       "\n",
       "      x     y    x2  ...      f759      f760      f761      f762      f763  \\\n",
       "5   493  1479   986  ... -0.243933  0.081438 -0.026993 -0.202966  0.186488   \n",
       "6   986   986  1479  ... -0.288985  0.087640  0.049662 -0.208533  0.235510   \n",
       "7  1479  1479  1972  ... -0.270145  0.070758 -0.028458 -0.210834  0.227700   \n",
       "8   493   986   986  ... -0.287041  0.121514 -0.008135 -0.220779  0.179901   \n",
       "9  1479   986  1972  ... -0.254537  0.080850 -0.013784 -0.200407  0.215601   \n",
       "\n",
       "       f764      f765      f766      f767      f768  \n",
       "5  0.202112 -0.260245 -0.378924  0.496770 -1.494687  \n",
       "6  0.152196 -0.247914 -0.395293  0.474001 -1.424915  \n",
       "7  0.216413 -0.248142 -0.398217  0.536445 -1.459662  \n",
       "8  0.202289 -0.235622 -0.422261  0.486641 -1.461829  \n",
       "9  0.180609 -0.256348 -0.401637  0.495235 -1.471664  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: (np.int64(1), np.int64(0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>isEng</th>\n",
       "      <th>same_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>train</th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>...</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1976</td>\n",
       "      <td>494</td>\n",
       "      <td>2470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254266</td>\n",
       "      <td>0.127310</td>\n",
       "      <td>-0.011507</td>\n",
       "      <td>-0.097587</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.329141</td>\n",
       "      <td>-0.268400</td>\n",
       "      <td>-0.457523</td>\n",
       "      <td>0.487944</td>\n",
       "      <td>-1.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310239</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>-0.130279</td>\n",
       "      <td>0.240916</td>\n",
       "      <td>0.205589</td>\n",
       "      <td>-0.290277</td>\n",
       "      <td>-0.437706</td>\n",
       "      <td>0.481369</td>\n",
       "      <td>-1.452869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1482</td>\n",
       "      <td>494</td>\n",
       "      <td>1976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.274421</td>\n",
       "      <td>0.140499</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>-0.153239</td>\n",
       "      <td>0.227730</td>\n",
       "      <td>0.235040</td>\n",
       "      <td>-0.259118</td>\n",
       "      <td>-0.435480</td>\n",
       "      <td>0.512737</td>\n",
       "      <td>-1.424407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>1482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239550</td>\n",
       "      <td>0.093602</td>\n",
       "      <td>-0.017014</td>\n",
       "      <td>-0.179545</td>\n",
       "      <td>0.203855</td>\n",
       "      <td>0.343389</td>\n",
       "      <td>-0.240150</td>\n",
       "      <td>-0.419020</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>-1.482068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unzipped/1_50/0001_3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>988</td>\n",
       "      <td>494</td>\n",
       "      <td>1482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234004</td>\n",
       "      <td>0.037380</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>-0.169868</td>\n",
       "      <td>0.214705</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>-0.324915</td>\n",
       "      <td>-0.407791</td>\n",
       "      <td>0.469555</td>\n",
       "      <td>-1.493571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    writer  isEng  same_text                 file_name  male  train  index  \\\n",
       "10       1      1          0  unzipped/1_50/0001_3.jpg     0      1     10   \n",
       "11       1      1          0  unzipped/1_50/0001_3.jpg     0      1     11   \n",
       "12       1      1          0  unzipped/1_50/0001_3.jpg     0      1     12   \n",
       "13       1      1          0  unzipped/1_50/0001_3.jpg     0      1     13   \n",
       "14       1      1          0  unzipped/1_50/0001_3.jpg     0      1     14   \n",
       "\n",
       "       x    y    x2  ...      f759      f760      f761      f762      f763  \\\n",
       "10  1976  494  2470  ... -0.254266  0.127310 -0.011507 -0.097587  0.210800   \n",
       "11   494  494   988  ... -0.310239  0.088337  0.010448 -0.130279  0.240916   \n",
       "12  1482  494  1976  ... -0.274421  0.140499  0.017490 -0.153239  0.227730   \n",
       "13   988  988  1482  ... -0.239550  0.093602 -0.017014 -0.179545  0.203855   \n",
       "14   988  494  1482  ... -0.234004  0.037380 -0.018710 -0.169868  0.214705   \n",
       "\n",
       "        f764      f765      f766      f767      f768  \n",
       "10  0.329141 -0.268400 -0.457523  0.487944 -1.518100  \n",
       "11  0.205589 -0.290277 -0.437706  0.481369 -1.452869  \n",
       "12  0.235040 -0.259118 -0.435480  0.512737 -1.424407  \n",
       "13  0.343389 -0.240150 -0.419020  0.517605 -1.482068  \n",
       "14  0.196334 -0.324915 -0.407791  0.469555 -1.493571  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: (np.int64(1), np.int64(1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>isEng</th>\n",
       "      <th>same_text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>train</th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>...</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1479</td>\n",
       "      <td>1972</td>\n",
       "      <td>1972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230391</td>\n",
       "      <td>0.100809</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>-0.217382</td>\n",
       "      <td>0.205409</td>\n",
       "      <td>0.214047</td>\n",
       "      <td>-0.273079</td>\n",
       "      <td>-0.402834</td>\n",
       "      <td>0.488653</td>\n",
       "      <td>-1.480792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>493</td>\n",
       "      <td>1479</td>\n",
       "      <td>986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281213</td>\n",
       "      <td>0.085982</td>\n",
       "      <td>0.038979</td>\n",
       "      <td>-0.181102</td>\n",
       "      <td>0.202569</td>\n",
       "      <td>0.286283</td>\n",
       "      <td>-0.251128</td>\n",
       "      <td>-0.440668</td>\n",
       "      <td>0.483774</td>\n",
       "      <td>-1.501802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>986</td>\n",
       "      <td>2465</td>\n",
       "      <td>1479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275889</td>\n",
       "      <td>0.120276</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>-0.174980</td>\n",
       "      <td>0.236136</td>\n",
       "      <td>0.237443</td>\n",
       "      <td>-0.236544</td>\n",
       "      <td>-0.449596</td>\n",
       "      <td>0.498428</td>\n",
       "      <td>-1.434339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>986</td>\n",
       "      <td>1972</td>\n",
       "      <td>1479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212950</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.024899</td>\n",
       "      <td>-0.171433</td>\n",
       "      <td>0.244673</td>\n",
       "      <td>0.180122</td>\n",
       "      <td>-0.272156</td>\n",
       "      <td>-0.365500</td>\n",
       "      <td>0.487081</td>\n",
       "      <td>-1.443907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unzipped/1_50/0001_4.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>493</td>\n",
       "      <td>1972</td>\n",
       "      <td>986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276774</td>\n",
       "      <td>0.106780</td>\n",
       "      <td>0.034823</td>\n",
       "      <td>-0.214603</td>\n",
       "      <td>0.227066</td>\n",
       "      <td>0.222292</td>\n",
       "      <td>-0.244637</td>\n",
       "      <td>-0.424428</td>\n",
       "      <td>0.481181</td>\n",
       "      <td>-1.470038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    writer  isEng  same_text                 file_name  male  train  index  \\\n",
       "15       1      1          1  unzipped/1_50/0001_4.jpg     0      1     15   \n",
       "16       1      1          1  unzipped/1_50/0001_4.jpg     0      1     16   \n",
       "17       1      1          1  unzipped/1_50/0001_4.jpg     0      1     17   \n",
       "18       1      1          1  unzipped/1_50/0001_4.jpg     0      1     18   \n",
       "19       1      1          1  unzipped/1_50/0001_4.jpg     0      1     19   \n",
       "\n",
       "       x     y    x2  ...      f759      f760      f761      f762      f763  \\\n",
       "15  1479  1972  1972  ... -0.230391  0.100809  0.022167 -0.217382  0.205409   \n",
       "16   493  1479   986  ... -0.281213  0.085982  0.038979 -0.181102  0.202569   \n",
       "17   986  2465  1479  ... -0.275889  0.120276  0.021062 -0.174980  0.236136   \n",
       "18   986  1972  1479  ... -0.212950  0.062496  0.024899 -0.171433  0.244673   \n",
       "19   493  1972   986  ... -0.276774  0.106780  0.034823 -0.214603  0.227066   \n",
       "\n",
       "        f764      f765      f766      f767      f768  \n",
       "15  0.214047 -0.273079 -0.402834  0.488653 -1.480792  \n",
       "16  0.286283 -0.251128 -0.440668  0.483774 -1.501802  \n",
       "17  0.237443 -0.236544 -0.449596  0.498428 -1.434339  \n",
       "18  0.180122 -0.272156 -0.365500  0.487081 -1.443907  \n",
       "19  0.222292 -0.244637 -0.424428  0.481181 -1.470038  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''grouped = train_FE.groupby(['isEng', 'same_text'])\n",
    "# Display the first five elements for each group in 'grouped'\n",
    "for group_name, group_df in grouped:\n",
    "    print(f\"Group: {group_name}\")\n",
    "    display(group_df.head(5))\n",
    "# groups 0,0 0,1 1,0 1,1\n",
    "# Select two group names (replace with actual group keys as needed)\n",
    "group_keys = list(grouped.groups.keys()) \n",
    "\n",
    "# Get the DataFrames for the first two groups\n",
    "df_arab_diff = grouped.get_group(group_keys[0])\n",
    "df_arab_same = grouped.get_group(group_keys[1])\n",
    "df_eng_diff = grouped.get_group(group_keys[2])\n",
    "df_eng_same = grouped.get_group(group_keys[3])\n",
    "\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "concatenated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.head()''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35cd78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FE=select_groups(train_FE,select_column='train', \n",
    "                       train_on_language=train_on_language, train_on_same=train_on_same)\n",
    "\n",
    "train_FE_selected = train_FE[train_FE['train']==1].copy()\n",
    "X = train_FE[train_FE['train']==1].drop(columns=cols_to_drop)\n",
    "y = train_FE[train_FE['train']==1][target_label]\n",
    "\n",
    "writers = train_FE[train_FE['train']==1]['writer']-1\n",
    "pages = train_FE[train_FE['train']==1]['page']\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ec822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5640 5640 5640\n",
      "Min writer ID: 0\n",
      "Max writer ID: 281\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y), len(writers))\n",
    "print(\"Min writer ID:\", writers.min())\n",
    "print(\"Max writer ID:\", writers.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cbb24f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selected_model = 'logreg' # 'gbm', 'lgbm', 'xgb', 'rf', 'mlp', 'dt', 'logreg'\n",
    "# Define the models\n",
    "gbm_classifier = GradientBoostingClassifier(\n",
    "    n_estimators=100, #100 is standard \n",
    "    learning_rate=0.1,  \n",
    "    max_depth=3,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#cat = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0, random_state=42)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(n_estimators=10, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "'''lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    num_leaves=20,\n",
    "    min_child_samples=30,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")'''\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128), activation='relu', solver='adam',\n",
    "                    max_iter=200, random_state=42, early_stopping=True, validation_fraction=0.1, n_iter_no_change=10)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_split=5, min_samples_leaf=2, ccp_alpha=0.01, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "feature_extraction_model = {'gbm': gbm_classifier, 'lgbm': lgbm, 'xgb': xgb, 'rf':rf, 'mlp':mlp, 'dt':dt,'logreg':logreg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e31548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#feature_extraction_model = {'gbm': gbm_classifier, 'cat': cat, 'lgbm': lgbm, 'xgb': xgb}\n",
    "# Define the pipeline\n",
    "if with_pca:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=0.95)  #384\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalize features\n",
    "        ('pca', pca),  # Apply PCA\n",
    "        (selected_model, feature_extraction_model[selected_model])  # Train GBM classifier\n",
    "    ])\n",
    "else:    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Normalize features\n",
    "        (selected_model, feature_extraction_model[selected_model])  # Train GBM classifier\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92a3aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def ensembled_predictions(base_preds,writers,mode='majority_vote',probs=None):\n",
    "    pred_df = pd.DataFrame({\n",
    "            'writer': writers,\n",
    "            'pred': base_preds\n",
    "        })\n",
    "    if probs is not None:\n",
    "        probs = np.abs(probs - 0.5) / 0.5\n",
    "        pred_df['prob'] = probs\n",
    "    if mode == 'majority_vote':\n",
    "        writer_preds = pred_df.groupby('writer')['pred'].agg(\n",
    "            lambda x: Counter(x).most_common(1)[0][0]\n",
    "        )\n",
    "    elif mode == 'weighted_vote':\n",
    "        if probs is None:\n",
    "            raise ValueError(\"For 'weighted_vote', 'probs' must be provided.\")\n",
    "        writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
    "            lambda x: pd.Series({\n",
    "                'writer_pred': round((x['pred'] * x['prob']).sum() / x['prob'].sum())\n",
    "            })\n",
    "        )['writer_pred'].astype(int)\n",
    "    elif mode == 'most_probable':\n",
    "        if probs is None:\n",
    "            raise ValueError(\"For 'most_probable', 'probs' must be provided.\")\n",
    "        writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
    "            lambda x: x.loc[x['prob'].idxmax(), 'pred']\n",
    "        )\n",
    "\n",
    "    # Step 5: Map writer-level prediction back to each sample\n",
    "    #final_preds = writers.map(writer_preds)\n",
    "    return writer_preds#final_preds.values\n",
    "\n",
    "def group_labels(y, writers):\n",
    "    \"\"\"\n",
    "    Groups labels by writer.\n",
    "    \"\"\"\n",
    "    grouped_labels = y.groupby(writers).agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "    return grouped_labels\n",
    "\n",
    "def compute_accuracies(y_true, y_pred, y_prob, pages, writers):\n",
    "    \"\"\"\n",
    "    Computes accuracy for each writer.\n",
    "    \"\"\"\n",
    "    accuracies = {}\n",
    "    accuracies['individual'] = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    grouped_true = group_labels(y_true, pages)\n",
    "    grouped_pred = ensembled_predictions(y_pred, pages)\n",
    "    accuracies['ensembled'] = accuracy_score(grouped_true, grouped_pred)\n",
    "\n",
    "    grouped_pred = ensembled_predictions(y_pred, pages, mode='weighted_vote',probs=y_prob)\n",
    "    accuracies['ensembled_weighted'] = accuracy_score(grouped_true, grouped_pred)\n",
    "\n",
    "    grouped_pred = ensembled_predictions(y_pred, pages, mode='most_probable',probs=y_prob)\n",
    "    accuracies['ensembled_most_probable'] = accuracy_score(grouped_true, grouped_pred)\n",
    "\n",
    "    grouped_true_writers = group_labels(y_true, writers)\n",
    "    grouped_pred_writers = ensembled_predictions(y_pred, writers)\n",
    "    accuracies['ensembled_writers'] = accuracy_score(grouped_true_writers, grouped_pred_writers)\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d960e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer\n",
      "1    1\n",
      "2    0\n",
      "Name: pred, dtype: int64\n",
      "1    1\n",
      "2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#test ensemble predictions function\n",
    "base_preds=pd.Series([1,0,0,0,1])\n",
    "test_writers= pd.Series([1, 1, 2, 2, 1])\n",
    "print(ensembled_predictions(base_preds, test_writers))\n",
    "base_labels = pd.Series([1,1,0,0,1])\n",
    "print(group_labels(base_labels, test_writers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "87232f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19 100 101 102 103 104 105 106 107 108 109]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Number of unique writers in val_idx: 57 -> 0.20212765957446807\n",
      "---------------------------------\n",
      "5018\n",
      "250\n",
      "0\n",
      "----------\n",
      "2648\n",
      "132\n",
      "1\n",
      "----------\n",
      "3427\n",
      "171\n",
      "0\n",
      "----------\n",
      "1728\n",
      "86\n",
      "0\n",
      "----------\n",
      "3171\n",
      "158\n",
      "1\n",
      "----------\n",
      "893\n",
      "44\n",
      "0\n",
      "----------\n",
      "970\n",
      "48\n",
      "1\n",
      "----------\n",
      "3572\n",
      "178\n",
      "1\n",
      "----------\n",
      "2304\n",
      "115\n",
      "0\n",
      "----------\n",
      "643\n",
      "32\n",
      "0\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#test grouping\n",
    "test_indices = np.random.choice(int(len(writers)*4/5), size=10, replace=False)\n",
    "for train_idx, val_idx in gkf.split(X, y, groups=writers):\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    print(val_idx[:30])\n",
    "    print(list(writers[val_idx][:30]))\n",
    "    print(\"Number of unique writers in val_idx:\", writers[val_idx].nunique(), \"->\", writers[val_idx].nunique()/ len(writers.unique()))\n",
    "    print(\"---------------------------------\")\n",
    "    for test_i in test_indices:\n",
    "        index=train_idx[test_i]\n",
    "        print(index)\n",
    "        print(writers[index])\n",
    "        label= y[index]\n",
    "        print(label)\n",
    "        X_test= X.loc[index]\n",
    "        print('----------')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dccd92ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model cross-val...\n",
      "Training on 4500 samples, validating on 1140 writers 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF accuracies {'individual': 0.7686666666666667, 'ensembled': 0.8088888888888889, 'ensembled_weighted': 0.82, 'ensembled_most_probable': 0.82, 'ensembled_writers': 0.8844444444444445}\n",
      "OOF accuracies {'individual': 0.7087719298245614, 'ensembled': 0.7149122807017544, 'ensembled_weighted': 0.7192982456140351, 'ensembled_most_probable': 0.7192982456140351, 'ensembled_writers': 0.8421052631578947}\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.719, Ensembled accuracy: 0.719, Individual accuracy: 0.684\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.719, Ensembled accuracy: 0.719, Individual accuracy: 0.733\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.719, Ensembled accuracy: 0.719, Individual accuracy: 0.719\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.702, Ensembled accuracy: 0.702, Individual accuracy: 0.698\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.719, Ensembled accuracy: 0.719, Individual accuracy: 0.709\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'all')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.789, Ensembled accuracy: 0.711, Individual accuracy: 0.709\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.825, Ensembled accuracy: 0.719, Individual accuracy: 0.702\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.789, Ensembled accuracy: 0.711, Individual accuracy: 0.716\n",
      "----------------------------------------\n",
      "Subgroup accuracies: {'english,different': {'individual': 0.6842105263157895, 'ensembled': 0.7192982456140351, 'ensembled_weighted': 0.6666666666666666, 'ensembled_most_probable': 0.7368421052631579, 'ensembled_writers': 0.7192982456140351}, 'english,same': {'individual': 0.7333333333333333, 'ensembled': 0.7192982456140351, 'ensembled_weighted': 0.7368421052631579, 'ensembled_most_probable': 0.7192982456140351, 'ensembled_writers': 0.7192982456140351}, 'arabic,different': {'individual': 0.7192982456140351, 'ensembled': 0.7192982456140351, 'ensembled_weighted': 0.7543859649122807, 'ensembled_most_probable': 0.7017543859649122, 'ensembled_writers': 0.7192982456140351}, 'arabic,same': {'individual': 0.6982456140350877, 'ensembled': 0.7017543859649122, 'ensembled_weighted': 0.7192982456140351, 'ensembled_most_probable': 0.7192982456140351, 'ensembled_writers': 0.7017543859649122}, 'english,all': {'individual': 0.7087719298245614, 'ensembled': 0.7192982456140351, 'ensembled_weighted': 0.7017543859649122, 'ensembled_most_probable': 0.7280701754385965, 'ensembled_writers': 0.7192982456140351}, 'arabic,all': {'individual': 0.7087719298245614, 'ensembled': 0.7105263157894737, 'ensembled_weighted': 0.7368421052631579, 'ensembled_most_probable': 0.7105263157894737, 'ensembled_writers': 0.7894736842105263}, 'all,different': {'individual': 0.7017543859649122, 'ensembled': 0.7192982456140351, 'ensembled_weighted': 0.7105263157894737, 'ensembled_most_probable': 0.7192982456140351, 'ensembled_writers': 0.8245614035087719}, 'all,same': {'individual': 0.7157894736842105, 'ensembled': 0.7105263157894737, 'ensembled_weighted': 0.7280701754385965, 'ensembled_most_probable': 0.7192982456140351, 'ensembled_writers': 0.7894736842105263}}\n",
      "-----------------------------*****************************---------------------------------------------\n",
      "Training on 4500 samples, validating on 1140 writers 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF accuracies {'individual': 0.76, 'ensembled': 0.81, 'ensembled_weighted': 0.8255555555555556, 'ensembled_most_probable': 0.8144444444444444, 'ensembled_writers': 0.8933333333333333}\n",
      "OOF accuracies {'individual': 0.7140350877192982, 'ensembled': 0.7543859649122807, 'ensembled_weighted': 0.7587719298245614, 'ensembled_most_probable': 0.7807017543859649, 'ensembled_writers': 0.7894736842105263}\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.789, Ensembled accuracy: 0.789, Individual accuracy: 0.730\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.772, Ensembled accuracy: 0.772, Individual accuracy: 0.733\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.754, Ensembled accuracy: 0.754, Individual accuracy: 0.702\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.702, Ensembled accuracy: 0.702, Individual accuracy: 0.691\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.789, Ensembled accuracy: 0.781, Individual accuracy: 0.732\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.719, Ensembled accuracy: 0.728, Individual accuracy: 0.696\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'different')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.772, Ensembled accuracy: 0.772, Individual accuracy: 0.716\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.702, Ensembled accuracy: 0.737, Individual accuracy: 0.712\n",
      "----------------------------------------\n",
      "Subgroup accuracies: {'english,different': {'individual': 0.7298245614035088, 'ensembled': 0.7894736842105263, 'ensembled_weighted': 0.8070175438596491, 'ensembled_most_probable': 0.8245614035087719, 'ensembled_writers': 0.7894736842105263}, 'english,same': {'individual': 0.7333333333333333, 'ensembled': 0.7719298245614035, 'ensembled_weighted': 0.7894736842105263, 'ensembled_most_probable': 0.7894736842105263, 'ensembled_writers': 0.7719298245614035}, 'arabic,different': {'individual': 0.7017543859649122, 'ensembled': 0.7543859649122807, 'ensembled_weighted': 0.7368421052631579, 'ensembled_most_probable': 0.7368421052631579, 'ensembled_writers': 0.7543859649122807}, 'arabic,same': {'individual': 0.6912280701754386, 'ensembled': 0.7017543859649122, 'ensembled_weighted': 0.7017543859649122, 'ensembled_most_probable': 0.7719298245614035, 'ensembled_writers': 0.7017543859649122}, 'english,all': {'individual': 0.7315789473684211, 'ensembled': 0.7807017543859649, 'ensembled_weighted': 0.7982456140350878, 'ensembled_most_probable': 0.8070175438596491, 'ensembled_writers': 0.7894736842105263}, 'arabic,all': {'individual': 0.6964912280701754, 'ensembled': 0.7280701754385965, 'ensembled_weighted': 0.7192982456140351, 'ensembled_most_probable': 0.7543859649122807, 'ensembled_writers': 0.7192982456140351}, 'all,different': {'individual': 0.7157894736842105, 'ensembled': 0.7719298245614035, 'ensembled_weighted': 0.7719298245614035, 'ensembled_most_probable': 0.7807017543859649, 'ensembled_writers': 0.7719298245614035}, 'all,same': {'individual': 0.712280701754386, 'ensembled': 0.7368421052631579, 'ensembled_weighted': 0.7456140350877193, 'ensembled_most_probable': 0.7807017543859649, 'ensembled_writers': 0.7017543859649122}}\n",
      "-----------------------------*****************************---------------------------------------------\n",
      "Training on 4520 samples, validating on 1120 writers 4520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF accuracies {'individual': 0.7743362831858407, 'ensembled': 0.8219026548672567, 'ensembled_weighted': 0.8329646017699115, 'ensembled_most_probable': 0.831858407079646, 'ensembled_writers': 0.9026548672566371}\n",
      "OOF accuracies {'individual': 0.6651785714285714, 'ensembled': 0.7098214285714286, 'ensembled_weighted': 0.7455357142857143, 'ensembled_most_probable': 0.71875, 'ensembled_writers': 0.7321428571428571}\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.750, Ensembled accuracy: 0.750, Individual accuracy: 0.671\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.750, Ensembled accuracy: 0.750, Individual accuracy: 0.675\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.643, Ensembled accuracy: 0.643, Individual accuracy: 0.639\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.696, Ensembled accuracy: 0.696, Individual accuracy: 0.675\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.768, Ensembled accuracy: 0.750, Individual accuracy: 0.673\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.696, Ensembled accuracy: 0.670, Individual accuracy: 0.657\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'different')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.679, Ensembled accuracy: 0.696, Individual accuracy: 0.655\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.732, Ensembled accuracy: 0.723, Individual accuracy: 0.675\n",
      "----------------------------------------\n",
      "Subgroup accuracies: {'english,different': {'individual': 0.6714285714285714, 'ensembled': 0.75, 'ensembled_weighted': 0.8214285714285714, 'ensembled_most_probable': 0.75, 'ensembled_writers': 0.75}, 'english,same': {'individual': 0.675, 'ensembled': 0.75, 'ensembled_weighted': 0.7678571428571429, 'ensembled_most_probable': 0.7321428571428571, 'ensembled_writers': 0.75}, 'arabic,different': {'individual': 0.6392857142857142, 'ensembled': 0.6428571428571429, 'ensembled_weighted': 0.6607142857142857, 'ensembled_most_probable': 0.6428571428571429, 'ensembled_writers': 0.6428571428571429}, 'arabic,same': {'individual': 0.675, 'ensembled': 0.6964285714285714, 'ensembled_weighted': 0.7321428571428571, 'ensembled_most_probable': 0.75, 'ensembled_writers': 0.6964285714285714}, 'english,all': {'individual': 0.6732142857142858, 'ensembled': 0.75, 'ensembled_weighted': 0.7946428571428571, 'ensembled_most_probable': 0.7410714285714286, 'ensembled_writers': 0.7678571428571429}, 'arabic,all': {'individual': 0.6571428571428571, 'ensembled': 0.6696428571428571, 'ensembled_weighted': 0.6964285714285714, 'ensembled_most_probable': 0.6964285714285714, 'ensembled_writers': 0.6964285714285714}, 'all,different': {'individual': 0.6553571428571429, 'ensembled': 0.6964285714285714, 'ensembled_weighted': 0.7410714285714286, 'ensembled_most_probable': 0.6964285714285714, 'ensembled_writers': 0.6785714285714286}, 'all,same': {'individual': 0.675, 'ensembled': 0.7232142857142857, 'ensembled_weighted': 0.75, 'ensembled_most_probable': 0.7410714285714286, 'ensembled_writers': 0.7321428571428571}}\n",
      "-----------------------------*****************************---------------------------------------------\n",
      "Training on 4520 samples, validating on 1120 writers 4520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF accuracies {'individual': 0.7621681415929203, 'ensembled': 0.8086283185840708, 'ensembled_weighted': 0.8230088495575221, 'ensembled_most_probable': 0.8207964601769911, 'ensembled_writers': 0.8761061946902655}\n",
      "OOF accuracies {'individual': 0.7098214285714286, 'ensembled': 0.7633928571428571, 'ensembled_weighted': 0.78125, 'ensembled_most_probable': 0.7767857142857143, 'ensembled_writers': 0.7857142857142857}\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.750, Ensembled accuracy: 0.750, Individual accuracy: 0.718\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.821, Ensembled accuracy: 0.821, Individual accuracy: 0.729\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.714, Ensembled accuracy: 0.714, Individual accuracy: 0.686\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.768, Ensembled accuracy: 0.768, Individual accuracy: 0.707\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.786, Ensembled accuracy: 0.786, Individual accuracy: 0.723\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'all')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.732, Ensembled accuracy: 0.741, Individual accuracy: 0.696\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.732, Ensembled accuracy: 0.732, Individual accuracy: 0.702\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.768, Ensembled accuracy: 0.795, Individual accuracy: 0.718\n",
      "----------------------------------------\n",
      "Subgroup accuracies: {'english,different': {'individual': 0.7178571428571429, 'ensembled': 0.75, 'ensembled_weighted': 0.7857142857142857, 'ensembled_most_probable': 0.7857142857142857, 'ensembled_writers': 0.75}, 'english,same': {'individual': 0.7285714285714285, 'ensembled': 0.8214285714285714, 'ensembled_weighted': 0.8214285714285714, 'ensembled_most_probable': 0.8035714285714286, 'ensembled_writers': 0.8214285714285714}, 'arabic,different': {'individual': 0.6857142857142857, 'ensembled': 0.7142857142857143, 'ensembled_weighted': 0.7321428571428571, 'ensembled_most_probable': 0.7142857142857143, 'ensembled_writers': 0.7142857142857143}, 'arabic,same': {'individual': 0.7071428571428572, 'ensembled': 0.7678571428571429, 'ensembled_weighted': 0.7857142857142857, 'ensembled_most_probable': 0.8035714285714286, 'ensembled_writers': 0.7678571428571429}, 'english,all': {'individual': 0.7232142857142857, 'ensembled': 0.7857142857142857, 'ensembled_weighted': 0.8035714285714286, 'ensembled_most_probable': 0.7946428571428571, 'ensembled_writers': 0.7857142857142857}, 'arabic,all': {'individual': 0.6964285714285714, 'ensembled': 0.7410714285714286, 'ensembled_weighted': 0.7589285714285714, 'ensembled_most_probable': 0.7589285714285714, 'ensembled_writers': 0.7321428571428571}, 'all,different': {'individual': 0.7017857142857142, 'ensembled': 0.7321428571428571, 'ensembled_weighted': 0.7589285714285714, 'ensembled_most_probable': 0.75, 'ensembled_writers': 0.7321428571428571}, 'all,same': {'individual': 0.7178571428571429, 'ensembled': 0.7946428571428571, 'ensembled_weighted': 0.8035714285714286, 'ensembled_most_probable': 0.8035714285714286, 'ensembled_writers': 0.7678571428571429}}\n",
      "-----------------------------*****************************---------------------------------------------\n",
      "Training on 4520 samples, validating on 1120 writers 4520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF accuracies {'individual': 0.7825221238938053, 'ensembled': 0.8252212389380531, 'ensembled_weighted': 0.8495575221238938, 'ensembled_most_probable': 0.8517699115044248, 'ensembled_writers': 0.9203539823008849}\n",
      "OOF accuracies {'individual': 0.6392857142857142, 'ensembled': 0.6785714285714286, 'ensembled_weighted': 0.6741071428571429, 'ensembled_most_probable': 0.6830357142857143, 'ensembled_writers': 0.6607142857142857}\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.679, Ensembled accuracy: 0.679, Individual accuracy: 0.639\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.696, Ensembled accuracy: 0.696, Individual accuracy: 0.664\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.554, Ensembled accuracy: 0.554, Individual accuracy: 0.557\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.786, Ensembled accuracy: 0.786, Individual accuracy: 0.696\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'all')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.732, Ensembled accuracy: 0.688, Individual accuracy: 0.652\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'all')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.696, Ensembled accuracy: 0.670, Individual accuracy: 0.627\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.625, Ensembled accuracy: 0.616, Individual accuracy: 0.598\n",
      "----------------------------------------\n",
      "Evaluating group: ('all', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy writer: 0.786, Ensembled accuracy: 0.741, Individual accuracy: 0.680\n",
      "----------------------------------------\n",
      "Subgroup accuracies: {'english,different': {'individual': 0.6392857142857142, 'ensembled': 0.6785714285714286, 'ensembled_weighted': 0.6964285714285714, 'ensembled_most_probable': 0.7142857142857143, 'ensembled_writers': 0.6785714285714286}, 'english,same': {'individual': 0.6642857142857143, 'ensembled': 0.6964285714285714, 'ensembled_weighted': 0.6964285714285714, 'ensembled_most_probable': 0.7321428571428571, 'ensembled_writers': 0.6964285714285714}, 'arabic,different': {'individual': 0.5571428571428572, 'ensembled': 0.5535714285714286, 'ensembled_weighted': 0.5892857142857143, 'ensembled_most_probable': 0.5892857142857143, 'ensembled_writers': 0.5535714285714286}, 'arabic,same': {'individual': 0.6964285714285714, 'ensembled': 0.7857142857142857, 'ensembled_weighted': 0.7142857142857143, 'ensembled_most_probable': 0.6964285714285714, 'ensembled_writers': 0.7857142857142857}, 'english,all': {'individual': 0.6517857142857143, 'ensembled': 0.6875, 'ensembled_weighted': 0.6964285714285714, 'ensembled_most_probable': 0.7232142857142857, 'ensembled_writers': 0.7321428571428571}, 'arabic,all': {'individual': 0.6267857142857143, 'ensembled': 0.6696428571428571, 'ensembled_weighted': 0.6517857142857143, 'ensembled_most_probable': 0.6428571428571429, 'ensembled_writers': 0.6964285714285714}, 'all,different': {'individual': 0.5982142857142857, 'ensembled': 0.6160714285714286, 'ensembled_weighted': 0.6428571428571429, 'ensembled_most_probable': 0.6517857142857143, 'ensembled_writers': 0.625}, 'all,same': {'individual': 0.6803571428571429, 'ensembled': 0.7410714285714286, 'ensembled_weighted': 0.7053571428571429, 'ensembled_most_probable': 0.7142857142857143, 'ensembled_writers': 0.7857142857142857}}\n",
      "-----------------------------*****************************---------------------------------------------\n",
      "Time taken to fit the model: 12.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_26080\\3402381078.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  writer_preds = pred_df.groupby('writer', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Measure the start time\n",
    "start_time = time.time()\n",
    "print(f\"Starting model cross-val...\")\n",
    "cross_val_accuracies = {\"IF\": [], \"OOF\": []}\n",
    "for train_idx, val_idx in gkf.split(X, y, groups=writers):\n",
    "    #print(train_idx)\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    X_train, y_train, writers_train, pages_train = shuffle(\n",
    "        X_train, y_train, writers.loc[train_idx], pages.loc[train_idx], random_state=42\n",
    "    )\n",
    "    print(f\"Training on {len(X_train)} samples, validating on {len(X_val)} writers {len(writers_train)}\")\n",
    "\n",
    "    # Fit the model on training data\n",
    "    pipeline.fit(X_train.values, y_train)\n",
    "    y_prob= pipeline.predict_proba(X_train.values)[:,1]\n",
    "    #y_pred = pipeline.predict(X_train.values)\n",
    "    y_pred=(y_prob>= 0.5).astype(int)\n",
    "    accuracies = compute_accuracies(y_train, y_pred, y_prob,pages_train,writers_train)\n",
    "    cross_val_accuracies[\"IF\"].append(accuracies)\n",
    "    print('IF accuracies', accuracies)\n",
    "    #print(f\"IF accuracies -> Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "\n",
    "    y_prob= pipeline.predict_proba(X_val.values)[:,1]\n",
    "    #y_pred = pipeline.predict(X_val.values)\n",
    "    y_pred=(y_prob >= 0.5).astype(int)\n",
    "    accuracies = compute_accuracies(y_val, y_pred, y_prob,pages.loc[val_idx], writers.loc[val_idx])\n",
    "    cross_val_accuracies[\"OOF\"].append(accuracies)\n",
    "    print('OOF accuracies', accuracies)\n",
    "    #print(f\"OOF accuracies -> Ensembled accuracy writers: {accuracies['ensembled_writers']:.3f}, Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "    #print(f\"Training on {len(X_train)} samples, validating on {len(X_val)} samples\")\n",
    "    subgroup_accuracies=compute_subgroup_accuracies(pipeline, train_FE_selected.loc[val_idx])\n",
    "    print(f\"Subgroup accuracies: {subgroup_accuracies}\")\n",
    "    print(\"-----------------------------*****************************---------------------------------------------\")\n",
    "\n",
    "# Measure the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time taken\n",
    "time_taken_cross_val = end_time - start_time\n",
    "print(f\"Time taken to fit the model: {time_taken_cross_val:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3fbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c1b745",
   "metadata": {},
   "source": [
    "# retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68f702c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining on all training data...\n",
      "[LightGBM] [Info] Number of positive: 2780, number of negative: 2860\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29325\n",
      "[LightGBM] [Info] Number of data points in the train set: 5640, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492908 -> initscore=-0.028371\n",
      "[LightGBM] [Info] Start training from score -0.028371\n",
      "Time taken to fit the model: 1.28 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"Retraining on all training data...\")\n",
    "pipeline.fit(X, y)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"Time taken to fit the model: {time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d37e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio by PCA: [0.27086154 0.14895208 0.08148499 0.05477929 0.03899795 0.0340924\n",
      " 0.02889819 0.02050937 0.018703   0.01674469 0.01499274 0.01372273\n",
      " 0.01118698 0.01065082 0.0102069  0.00928136 0.00741702 0.00688391\n",
      " 0.00668457 0.00538263 0.00525704 0.00501755 0.00490214 0.00447999\n",
      " 0.00414312 0.00391832 0.00382237 0.00373094 0.00353072 0.00348215\n",
      " 0.00338362 0.0032251  0.00306907 0.00282812 0.00262151 0.00247765\n",
      " 0.00233217 0.00233077 0.00228889 0.00214704 0.00209126 0.00200259\n",
      " 0.00192751 0.0018739  0.00185081 0.00175507 0.00171918 0.0016803\n",
      " 0.00166548 0.00159953 0.00153799 0.00150362 0.00146323 0.00145204\n",
      " 0.00136959 0.00133634 0.00129349 0.00126573 0.0012568  0.00122379\n",
      " 0.00117126 0.00113983 0.00111068 0.00106524 0.0010635  0.00104219\n",
      " 0.001025   0.00099638 0.00098295 0.00094427 0.00092341 0.00090255\n",
      " 0.00089064 0.00086622 0.0008609  0.00084022 0.00080507 0.00079492\n",
      " 0.00078686 0.00077203 0.00076686 0.00076166 0.00073198 0.0007137\n",
      " 0.0007078  0.00068814 0.0006832  0.00066693 0.00065401 0.00063858\n",
      " 0.00062805 0.00062416 0.00060742 0.00059834 0.00058286 0.00056827\n",
      " 0.00056344 0.00055455 0.0005514  0.00054154 0.00053643 0.00052633\n",
      " 0.00051426 0.00051141 0.00050548 0.00049785 0.00049241 0.0004878\n",
      " 0.00048423 0.00047564 0.00047152 0.00046756 0.00046022 0.00044715\n",
      " 0.00044263]\n",
      "Number of features used after PCA: 115\n"
     ]
    }
   ],
   "source": [
    "if with_pca:\n",
    "    pca = pipeline.named_steps['pca']\n",
    "    print(f\"Explained variance ratio by PCA: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Number of features used after PCA: {pca.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50ebc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\GeneralPurposeML\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\andre\\anaconda3\\envs\\GeneralPurposeML\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\andre\\anaconda3\\envs\\GeneralPurposeML\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\andre\\anaconda3\\envs\\GeneralPurposeML\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on all training data -> Ensembled accuracy: 0.926, Individual accuracy: 0.769\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.876, Individual accuracy: 0.786\n",
      "----------------------------------------\n",
      "Evaluating group: ('english', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.833, Individual accuracy: 0.772\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'different')\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.840, Individual accuracy: 0.754\n",
      "----------------------------------------\n",
      "Evaluating group: ('arabic', 'same')\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.844, Individual accuracy: 0.764\n",
      "----------------------------------------\n",
      "Evaluating group: english,different+same\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.855, Individual accuracy: 0.779\n",
      "----------------------------------------\n",
      "Evaluating group: arabic,different+same\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.848, Individual accuracy: 0.766\n",
      "----------------------------------------\n",
      "Evaluating group: english+arabic,different\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.858, Individual accuracy: 0.770\n",
      "----------------------------------------\n",
      "Evaluating group: english+arabic,same\n",
      "Accuracy on subgroup -> Ensembled accuracy: 0.846, Individual accuracy: 0.771\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\GeneralPurposeML\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Iterate over all possible non-empty subgroups of group indices [0, 1, 2, 3]\\nall_indices = [0, 1, 2, 3]\\nfor r in [2,4]:\\n    for idxs in combinations(all_indices, r):\\n        subgroup_sizes = [group_sizes[i] for i in idxs]\\n        subgroup_accuracies = [accuracies[i] for i in idxs]\\n        weighted_mean = np.average(subgroup_accuracies, weights=subgroup_sizes)\\n        languages = [groups[i][0] for i in idxs]\\n        same_texts = [groups[i][1] for i in idxs]\\n        print(f\"Weighted mean accuracy for {languages} and {same_texts}: {weighted_mean:.4f}\")'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "subgroup_accuracies = {}\n",
    "# Predict on train data\n",
    "y_pred = pipeline.predict(X)\n",
    "accuracies = compute_accuracies(y, y_pred, writers)\n",
    "subgroup_accuracies['english+arabic,different+same'] = accuracies\n",
    "print(f\"Training Accuracy on all training data -> Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "training_accuracy = accuracy_score(y, y_pred)\n",
    "print('----------------------------------------')\n",
    "groups = [('english','different'), ('english','same'), ('arabic','different'), ('arabic','same')]\n",
    "group_sizes = []\n",
    "for group in groups:\n",
    "    print(f\"Evaluating group: {group}\")\n",
    "    train_FE=select_groups(train_FE,select_column='train', \n",
    "                        train_on_language=group[0], train_on_same=group[1])\n",
    "    X_s = train_FE[train_FE['train']==1].drop(columns=cols_to_drop)\n",
    "    y_s = train_FE[train_FE['train']==1][target_label]\n",
    "    writers_s = train_FE[train_FE['train']==1]['writer']-1\n",
    "    group_sizes.append(len(X_s))\n",
    "    y_pred = pipeline.predict(X_s)\n",
    "    accuracies = compute_accuracies(y_s, y_pred, writers_s)\n",
    "    subgroup_accuracies[f'{group[0]},{group[1]}'] = accuracies\n",
    "    print(f\"Accuracy on subgroup -> Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "    print('----------------------------------------')\n",
    "groups_joined = [(0,1),(2,3),(0,2),(1,3)]\n",
    "for group in groups_joined:\n",
    "    language_1,same_1 = groups[group[0]]\n",
    "    language_2,same_2 = groups[group[1]]\n",
    "    if language_1 == language_2:\n",
    "        first= f'{language_1}'\n",
    "    else:\n",
    "        first = f'{language_1}+{language_2}'\n",
    "    if same_1 == same_2:\n",
    "        second = f'{same_1}'\n",
    "    else:\n",
    "        second = f'{same_1}+{same_2}'\n",
    "    group_name= f'{first},{second}'\n",
    "    print(f\"Evaluating group: {group_name}\")\n",
    "    sub_group_sizes = [group_sizes[group[0]], group_sizes[group[1]]]\n",
    "    sub_group_accuracies = [subgroup_accuracies[f'{language_1},{same_1}'], subgroup_accuracies[f'{language_2},{same_2}']]\n",
    "    accuracies['ensembled'] = np.average([g['ensembled'] for g in sub_group_accuracies], weights=sub_group_sizes)\n",
    "    accuracies['individual'] = np.average([g['individual'] for g in sub_group_accuracies], weights=sub_group_sizes)\n",
    "    subgroup_accuracies[f'{group_name}'] = accuracies\n",
    "    print(f\"Accuracy on subgroup -> Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "    print('----------------------------------------')\n",
    "'''# Iterate over all possible non-empty subgroups of group indices [0, 1, 2, 3]\n",
    "all_indices = [0, 1, 2, 3]\n",
    "for r in [2,4]:\n",
    "    for idxs in combinations(all_indices, r):\n",
    "        subgroup_sizes = [group_sizes[i] for i in idxs]\n",
    "        subgroup_accuracies = [accuracies[i] for i in idxs]\n",
    "        weighted_mean = np.average(subgroup_accuracies, weights=subgroup_sizes)\n",
    "        languages = [groups[i][0] for i in idxs]\n",
    "        same_texts = [groups[i][1] for i in idxs]\n",
    "        print(f\"Weighted mean accuracy for {languages} and {same_texts}: {weighted_mean:.4f}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0f6c8f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english+arabic,different+same': {'ensembled': 0.8368794326241135, 'individual': 0.7716312056737589}, 'english,different': {'ensembled': 0.8794326241134752, 'individual': 0.7936170212765957}, 'english,same': {'ensembled': 0.8333333333333334, 'individual': 0.7780141843971631}, 'arabic,different': {'ensembled': 0.8404255319148937, 'individual': 0.7936170212765957}, 'arabic,same': {'ensembled': np.float64(0.8466312056737588), 'individual': np.float64(0.7858156028368795)}, 'english,different+same': {'ensembled': np.float64(0.8466312056737588), 'individual': np.float64(0.7858156028368795)}, 'arabic,different+same': {'ensembled': np.float64(0.8466312056737588), 'individual': np.float64(0.7858156028368795)}, 'english+arabic,different': {'ensembled': np.float64(0.8466312056737588), 'individual': np.float64(0.7858156028368795)}, 'english+arabic,same': {'ensembled': np.float64(0.8466312056737588), 'individual': np.float64(0.7858156028368795)}}\n"
     ]
    }
   ],
   "source": [
    "print(subgroup_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9deb3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path: c:\\Users\\andre\\VsCode\\PD related projects\\gender_detection\\outputs\\logs\\feature_extraction_metadata_log.json\n",
      "Updated log for experiment 20250528_144225\n"
     ]
    }
   ],
   "source": [
    "experiment = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = os.path.join(source_path, \"outputs\", \"logs\")\n",
    "# Example usage:\n",
    "LOG_OUT_FILE = out_dir+\"\\\\feature_extraction_metadata_log.json\"\n",
    "print(f\"Log file path: {LOG_OUT_FILE}\")\n",
    "file_IO.add_or_update_experiment(\n",
    "    experiment, LOG_OUT_FILE,\n",
    "    custom_metadata={\n",
    "        \"type of preprocessing\": extracted_from,\n",
    "        \"original raw file\": source_data,\n",
    "        \"input file\": input_file_name,\n",
    "        \"FE model\": model_used,\n",
    "        \"FE transform\": transform_used,\n",
    "        \"classifier model\": selected_model,\n",
    "        \"model_params\": feature_extraction_model[selected_model].get_params(),\n",
    "        \"n_splits\": n_splits,\n",
    "        \"train_on_language\": train_on_language,\n",
    "        \"train_on_same\": train_on_same,\n",
    "        \"task\": task,\n",
    "        \"with cross validation\": with_cross_validation,\n",
    "        \"with PCA\": with_pca,\n",
    "        \"training time for cross-validation\": time_taken_cross_val,\n",
    "        \"training time for final model\": time_taken,\n",
    "        \"cross_val_accuracies\": cross_val_accuracies,\n",
    "        \"subgroup_accuracies\": subgroup_accuracies,\n",
    "        \"is_kaggle\": is_kaggle,\n",
    "        \"test\": 'this is a test column',\n",
    "        \"description\": ''' I am training a classifier on the feature vectors extracted by a deep model\n",
    "        I am evaluating the results on subsets of the training data, based on language and same/different text.''' \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e13f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7024107",
   "metadata": {},
   "source": [
    "# easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eaf8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.file_IO as file_IO\n",
    "    \n",
    "\n",
    "    importlib.reload(file_IO)\n",
    "\n",
    "    return file_IO\n",
    "\n",
    "file_IO = reload_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7d4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_groups(train_FE,select_column='train', train_on_language='arabic', train_on_same='same'):\n",
    "    train_FE[select_column] = 1\n",
    "    if train_on_language=='arabic':\n",
    "        train_FE.loc[train_FE['isEng'] == 1, select_column] = 0 #remove english\n",
    "    elif train_on_language=='english':\n",
    "        train_FE.loc[train_FE['isEng'] == 0, select_column] = 0 #remove arabic\n",
    "    else:\n",
    "        pass\n",
    "    if train_on_same=='same':\n",
    "        train_FE.loc[train_FE['same_text'] == 0, select_column] = 0 #remove different texts\n",
    "    elif train_on_same=='different':\n",
    "        train_FE.loc[train_FE['same_text'] == 1, select_column] = 0 #remove same texts\n",
    "    else:\n",
    "        pass\n",
    "    return train_FE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7509edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgroup_accuracies(pipeline, train_df):\n",
    "    subgroup_accuracies = {}\n",
    "    groups = [('english','different'), ('english','same'), ('arabic','different'), ('arabic','same'),\n",
    "              ('english','all'), ('arabic','all'), ('all','different'), ('all','same')]\n",
    "    group_sizes = []\n",
    "    acc_keys=None\n",
    "    for group in groups:\n",
    "        print(f\"Evaluating group: {group}\")\n",
    "        train_df=select_groups(train_df,select_column='train', \n",
    "                            train_on_language=group[0], train_on_same=group[1])\n",
    "        X_s = train_df[train_df['train']==1].drop(columns=cols_to_drop)\n",
    "        y_s = train_df[train_df['train']==1][target_label]\n",
    "        writers_s = train_df[train_df['train']==1]['writer']-1\n",
    "        pages_s = train_df[train_df['train']==1]['page']\n",
    "        group_sizes.append(len(X_s))\n",
    "\n",
    "        y_prob= pipeline.predict_proba(X_s.values)[:,1]\n",
    "        #y_pred = pipeline.predict(X_s.values)\n",
    "        y_pred=(y_prob >= 0.5).astype(int)\n",
    "        accuracies = compute_accuracies(y_s, y_pred, y_prob, pages_s,writers_s)\n",
    "        subgroup_accuracies[f'{group[0]},{group[1]}'] = accuracies\n",
    "        if acc_keys==None:\n",
    "            acc_keys = list(accuracies.keys())\n",
    "        print(f\"Accuracy on subgroup -> Ensembled accuracy writer: {accuracies['ensembled_writers']:.3f}, Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "        print('----------------------------------------')\n",
    "    return subgroup_accuracies\n",
    "    '''groups_joined = [(0,1),(2,3),(0,2),(1,3)]\n",
    "    for group in groups_joined:\n",
    "        language_1,same_1 = groups[group[0]]\n",
    "        language_2,same_2 = groups[group[1]]\n",
    "        if language_1 == language_2:\n",
    "            first= f'{language_1}'\n",
    "        else:\n",
    "            first = f'{language_1}+{language_2}'\n",
    "        if same_1 == same_2:\n",
    "            second = f'{same_1}'\n",
    "        else:\n",
    "            second = f'{same_1}+{same_2}'\n",
    "        group_name= f'{first},{second}'\n",
    "        print(f\"Evaluating group: {group_name}\")\n",
    "        sub_group_sizes = [group_sizes[group[0]], group_sizes[group[1]]]\n",
    "        sub_group_accuracies = [subgroup_accuracies[f'{language_1},{same_1}'], subgroup_accuracies[f'{language_2},{same_2}']]\n",
    "        for key in acc_keys:\n",
    "            accuracies[key] = np.average([g[key] for g in sub_group_accuracies], weights=sub_group_sizes)\n",
    "        subgroup_accuracies[f'{group_name}'] = accuracies\n",
    "        print(f\"Accuracy on subgroup -> Ensembled accuracy writer: {accuracies['ensembled_writers']:.3f}, Ensembled accuracy: {accuracies['ensembled']:.3f}, Individual accuracy: {accuracies['individual']:.3f}\")\n",
    "        print('----------------------------------------')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
