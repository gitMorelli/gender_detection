{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ce5454",
   "metadata": {},
   "source": [
    "This notebook takes the icdar training data and generates a csv file with writer,same_text,isEng,train,file_name,male columns (file_name is the absolute path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8d69799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e19e7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test functions\n",
    "def male_counts(sex_df):\n",
    "    # Get the counts of each unique value in the \"male\" column\n",
    "    male_counts = sex_df['male'].value_counts(dropna=False)\n",
    "\n",
    "    # Print the counts\n",
    "    print(\"Number of times 'male' is 0:\", male_counts.get(0, 0))\n",
    "    print(\"Number of times 'male' is 1:\", male_counts.get(1, 0))\n",
    "    print(\"Number of times 'male' is something else:\", len(sex_df) - male_counts.get(0, 0) - male_counts.get(1, 0))\n",
    "def check_if_both(train_df, column_name='same_text'):\n",
    "    # Group by writer and check if both same_text=1 and same_text=0 are present\n",
    "    writer_groups = train_df.groupby('writer')[column_name].nunique()\n",
    "\n",
    "    # Filter writers that do not have both same_text=1 and same_text=0\n",
    "    writers_missing_both = writer_groups[writer_groups != 2]\n",
    "\n",
    "    if writers_missing_both.empty:\n",
    "        print(f\"All writers have both {column_name}=1 and {column_name}=0.\")\n",
    "    else:\n",
    "        print(f\"The following writers do not have {column_name}=1 and {column_name}=0\")\n",
    "        print(writers_missing_both)\n",
    "def check_randomization(train_df):\n",
    "    # Get the number of rows where train == 1\n",
    "    train_1_count = train_df[train_df['train'] == 1].shape[0]\n",
    "\n",
    "    # Calculate the fraction\n",
    "    train_1_fraction = train_1_count / train_df.shape[0]\n",
    "\n",
    "    print(f\"Number of rows where train == 1: {train_1_count}\")\n",
    "    print(f\"Fraction of rows where train == 1: {train_1_fraction:.2f}\")\n",
    "def check_grouping(train_df):\n",
    "    # Group by writer and check if the train column has a constant value\n",
    "    constant_train_check = train_df.groupby('writer')['train'].nunique()\n",
    "\n",
    "    # Find writers where the train column is not constant\n",
    "    non_constant_writers = constant_train_check[constant_train_check > 1]\n",
    "\n",
    "    if non_constant_writers.empty:\n",
    "        print(\"The train column is constant for all writers.\")\n",
    "    else:\n",
    "        print(\"The train column is not constant for the following writers:\")\n",
    "        print(non_constant_writers)\n",
    "def check_occurrences(train_df):\n",
    "    # Count the occurrences of each unique writer value\n",
    "    writer_counts = train_df['writer'].value_counts()\n",
    "\n",
    "    # Check if all writers have exactly 4 occurrences\n",
    "    if (writer_counts == 4).all():\n",
    "        print(\"Each unique writer value occurs on exactly 4 rows.\")\n",
    "    else:\n",
    "        print(\"Some writers do not occur exactly 4 times.\")\n",
    "        print(writer_counts[writer_counts != 4])\n",
    "def check_title_association(train_df):\n",
    "    random_numbers = random.sample(range(1, 282*4+1), 10)\n",
    "    for n in random_numbers:\n",
    "        print(n)\n",
    "        print(train_df['file_name'][n])\n",
    "        print(train_df['writer'][n],train_df['isEng'][n], train_df['same_text'][n])\n",
    "        print('-------------')\n",
    "def check_sex_association(train_df,sex_df):\n",
    "    random_numbers = random.sample(range(1, 283), 10)\n",
    "    for n in random_numbers:\n",
    "        print(n)\n",
    "        print(train_df[train_df['writer'] == n][['writer','male']])\n",
    "        print(sex_df[sex_df['writer'] == n][['writer','male']])\n",
    "        print('-------------')\n",
    "def check_if_seed(train_df):\n",
    "    train_0_writers = train_df[train_df['train'] == 0]['writer'].unique().tolist()\n",
    "    train_1_writers = train_df[train_df['train'] == 1]['writer'].unique().tolist()\n",
    "    return train_0_writers, train_1_writers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0102914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "seed=42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ff9dca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PATH=\"D:\\\\download\\\\PD project\\\\datasets\\\\ICDAR 2013 - Gender Identification Competition Dataset\"\n",
    "image_PATH=data_PATH+\"\\\\unzipped\"\n",
    "source_path=\"D:\\\\burtm\\\\Visual_studio_code\\\\PD_related_projects\"\n",
    "train_df_complete = pd.read_csv(os.path.join(data_PATH, \"train\\\\train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4f0ba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>page_id</th>\n",
       "      <th>language</th>\n",
       "      <th>same_text</th>\n",
       "      <th>tortuosityHist10[0]</th>\n",
       "      <th>tortuosityHist10[1]</th>\n",
       "      <th>tortuosityHist10[2]</th>\n",
       "      <th>tortuosityHist10[3]</th>\n",
       "      <th>tortuosityHist10[4]</th>\n",
       "      <th>tortuosityHist10[5]</th>\n",
       "      <th>...</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[210]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[211]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[212]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[213]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[214]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[215]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[216]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[217]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[218]</th>\n",
       "      <th>directions_hist1a2a3a4a5a6a7a8a9a10_220[219]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.004804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.004706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.004547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92875</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.004354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 7070 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  page_id language  same_text  tortuosityHist10[0]  \\\n",
       "0       1        1   Arabic          0              1.00000   \n",
       "1       1        2   Arabic          1              1.00000   \n",
       "2       1        3  English          0              1.00000   \n",
       "3       1        4  English          1              1.00000   \n",
       "4       2        1   Arabic          0              1.00000   \n",
       "5       2        2   Arabic          1              1.00000   \n",
       "6       2        3  English          0              1.00000   \n",
       "7       2        4  English          1              1.00000   \n",
       "8       3        1   Arabic          0              1.00000   \n",
       "9       3        2   Arabic          1              0.92875   \n",
       "\n",
       "   tortuosityHist10[1]  tortuosityHist10[2]  tortuosityHist10[3]  \\\n",
       "0             0.000000             0.000000                  0.0   \n",
       "1             0.000000             0.000000                  0.0   \n",
       "2             0.000000             0.000000                  0.0   \n",
       "3             0.000000             0.000000                  0.0   \n",
       "4             0.000000             0.000000                  0.0   \n",
       "5             0.000000             0.000000                  0.0   \n",
       "6             0.000000             0.000000                  0.0   \n",
       "7             0.000000             0.000000                  0.0   \n",
       "8             0.000000             0.000000                  0.0   \n",
       "9             0.004071             0.001876                  0.0   \n",
       "\n",
       "   tortuosityHist10[4]  tortuosityHist10[5]  ...  \\\n",
       "0             0.000000             0.000000  ...   \n",
       "1             0.000000             0.000000  ...   \n",
       "2             0.000000             0.000000  ...   \n",
       "3             0.000000             0.000000  ...   \n",
       "4             0.000000             0.000000  ...   \n",
       "5             0.000000             0.000000  ...   \n",
       "6             0.000000             0.000000  ...   \n",
       "7             0.000000             0.000000  ...   \n",
       "8             0.000000             0.000000  ...   \n",
       "9             0.018031             0.025427  ...   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[210]  \\\n",
       "0                                      0.002457   \n",
       "1                                      0.002498   \n",
       "2                                      0.002090   \n",
       "3                                      0.002435   \n",
       "4                                      0.002465   \n",
       "5                                      0.002535   \n",
       "6                                      0.002887   \n",
       "7                                      0.002946   \n",
       "8                                      0.002245   \n",
       "9                                      0.002179   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[211]  \\\n",
       "0                                      0.002633   \n",
       "1                                      0.002641   \n",
       "2                                      0.002440   \n",
       "3                                      0.002823   \n",
       "4                                      0.002724   \n",
       "5                                      0.002808   \n",
       "6                                      0.003271   \n",
       "7                                      0.003295   \n",
       "8                                      0.002325   \n",
       "9                                      0.002267   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[212]  \\\n",
       "0                                      0.002698   \n",
       "1                                      0.002836   \n",
       "2                                      0.002831   \n",
       "3                                      0.003117   \n",
       "4                                      0.003079   \n",
       "5                                      0.002942   \n",
       "6                                      0.003569   \n",
       "7                                      0.003569   \n",
       "8                                      0.002383   \n",
       "9                                      0.002385   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[213]  \\\n",
       "0                                      0.002929   \n",
       "1                                      0.002999   \n",
       "2                                      0.003078   \n",
       "3                                      0.003441   \n",
       "4                                      0.003305   \n",
       "5                                      0.003151   \n",
       "6                                      0.003793   \n",
       "7                                      0.003846   \n",
       "8                                      0.002515   \n",
       "9                                      0.002550   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[214]  \\\n",
       "0                                      0.003014   \n",
       "1                                      0.003246   \n",
       "2                                      0.003438   \n",
       "3                                      0.003788   \n",
       "4                                      0.003425   \n",
       "5                                      0.003247   \n",
       "6                                      0.004049   \n",
       "7                                      0.004083   \n",
       "8                                      0.002725   \n",
       "9                                      0.002723   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[215]  \\\n",
       "0                                      0.003225   \n",
       "1                                      0.003456   \n",
       "2                                      0.003732   \n",
       "3                                      0.004056   \n",
       "4                                      0.003403   \n",
       "5                                      0.003246   \n",
       "6                                      0.004214   \n",
       "7                                      0.004329   \n",
       "8                                      0.003046   \n",
       "9                                      0.002836   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[216]  \\\n",
       "0                                      0.003572   \n",
       "1                                      0.003709   \n",
       "2                                      0.004100   \n",
       "3                                      0.004285   \n",
       "4                                      0.003450   \n",
       "5                                      0.003433   \n",
       "6                                      0.004339   \n",
       "7                                      0.004566   \n",
       "8                                      0.003304   \n",
       "9                                      0.003049   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[217]  \\\n",
       "0                                      0.003957   \n",
       "1                                      0.003994   \n",
       "2                                      0.004329   \n",
       "3                                      0.004527   \n",
       "4                                      0.003626   \n",
       "5                                      0.003516   \n",
       "6                                      0.004598   \n",
       "7                                      0.004850   \n",
       "8                                      0.003629   \n",
       "9                                      0.003374   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[218]  \\\n",
       "0                                      0.004232   \n",
       "1                                      0.004308   \n",
       "2                                      0.004687   \n",
       "3                                      0.004843   \n",
       "4                                      0.003977   \n",
       "5                                      0.003787   \n",
       "6                                      0.004874   \n",
       "7                                      0.005092   \n",
       "8                                      0.004037   \n",
       "9                                      0.003757   \n",
       "\n",
       "   directions_hist1a2a3a4a5a6a7a8a9a10_220[219]  \n",
       "0                                      0.004804  \n",
       "1                                      0.004706  \n",
       "2                                      0.004879  \n",
       "3                                      0.005085  \n",
       "4                                      0.004547  \n",
       "5                                      0.004377  \n",
       "6                                      0.005211  \n",
       "7                                      0.005397  \n",
       "8                                      0.004564  \n",
       "9                                      0.004354  \n",
       "\n",
       "[10 rows x 7070 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_complete.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "13f20fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    writer  male\n",
       "0        1     0\n",
       "1        2     0\n",
       "2        3     0\n",
       "3        4     0\n",
       "4        5     1\n",
       "5        6     1\n",
       "6        7     1\n",
       "7        8     1\n",
       "8        9     0\n",
       "9       10     1\n",
       "10      11     0\n",
       "11      12     1\n",
       "12      13     0\n",
       "13      14     1\n",
       "14      15     1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_df = pd.read_csv(os.path.join(data_PATH, \"train_answers.csv\"),delimiter=',')\n",
    "sex_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b86b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times 'male' is 0: 143\n",
      "Number of times 'male' is 1: 139\n",
      "Number of times 'male' is something else: 0\n"
     ]
    }
   ],
   "source": [
    "male_counts(sex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a75e66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\burtm\\AppData\\Local\\Temp\\ipykernel_12808\\4054552359.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['isEng'] = language_dummies.iloc[:, 0].astype(int)\n",
      "C:\\Users\\burtm\\AppData\\Local\\Temp\\ipykernel_12808\\4054552359.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop(columns=['language'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng\n",
       "0       1          0      0\n",
       "1       1          1      0\n",
       "2       1          0      1\n",
       "3       1          1      1\n",
       "4       2          0      0\n",
       "5       2          1      0\n",
       "6       2          0      1\n",
       "7       2          1      1\n",
       "8       3          0      0\n",
       "9       3          1      0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['writer', 'language', 'same_text']\n",
    "train_df = train_df_complete[selected_columns]\n",
    "\n",
    "# Convert the 'language' column to binary columns\n",
    "language_dummies = pd.get_dummies(train_df['language'], drop_first=True)\n",
    "\n",
    "# Add the binary column to the dataframe\n",
    "train_df['isEng'] = language_dummies.iloc[:, 0].astype(int)\n",
    "\n",
    "# Drop the original 'language' column\n",
    "train_df.drop(columns=['language'], inplace=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d16d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All writers have both same_text=1 and same_text=0.\n",
      "All writers have both isEng=1 and isEng=0.\n"
     ]
    }
   ],
   "source": [
    "check_if_both(train_df)\n",
    "check_if_both(train_df, column_name='isEng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f0992c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train\n",
       "0       1          0      0      1\n",
       "1       1          1      0      1\n",
       "2       1          0      1      1\n",
       "3       1          1      1      1\n",
       "4       2          0      0      1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the probability of being 0\n",
    "p_train = 0.9\n",
    "N=282\n",
    "\n",
    "# Create a dataframe with writer column from 1 to 282\n",
    "writers_df = pd.DataFrame({'writer': np.arange(1, N+1)})\n",
    "\n",
    "# Add a train column that is randomly 0 or 1 with probability p of being 0\n",
    "writers_df['train'] = np.random.choice([0, 1], size=len(writers_df), p=[1-p_train, p_train])\n",
    "\n",
    "# Merge with the train_df dataframe on the writer column\n",
    "train_df = train_df.merge(writers_df, on='writer', how='left')\n",
    "\n",
    "# Display the dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5bc6e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 11, 30, 33, 38, 43, 57, 59, 69, 73, 78, 84, 99, 101, 110, 129, 146, 149, 165, 169, 172, 191, 202, 206, 209, 223, 238, 245, 260]\n",
      "val should be (previous run): \n",
      " [7, 11, 30, 33, 38, 43, 57, 59, 69, 73, 78, 84, 99, 101, 110, 129, 146, 149, 165, 169, 172, 191, 202, 206, 209, 223, 238, 245, 260])\n"
     ]
    }
   ],
   "source": [
    "val,train = check_if_seed(train_df)\n",
    "print(val)\n",
    "print('val should be (previous run): \\n [7, 11, 30, 33, 38, 43, 57, 59, 69, 73, 78, 84, 99, 101, 110, 129, 146, 149, 165, 169, 172, 191, 202, 206, 209, 223, 238, 245, 260])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1083cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where train == 1: 1012\n",
      "Fraction of rows where train == 1: 0.90\n"
     ]
    }
   ],
   "source": [
    "check_randomization(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8edd985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train column is constant for all writers.\n"
     ]
    }
   ],
   "source": [
    "check_grouping(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5059ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each unique writer value occurs on exactly 4 rows.\n"
     ]
    }
   ],
   "source": [
    "check_occurrences(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "562b9ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_50', '51_100', '101_150', '151_200', '201_250', '251_300']\n"
     ]
    }
   ],
   "source": [
    "folder_names = [folder for folder in os.listdir(image_PATH) if os.path.isdir(os.path.join(image_PATH, folder))]\n",
    "# Extract the X part from the folder names\n",
    "x_values = [int(folder.split('_')[0]) for folder in folder_names]\n",
    "\n",
    "# Sort both lists based on the X values\n",
    "sorted_indices = sorted(range(len(x_values)), key=lambda k: x_values[k])\n",
    "folder_names = [folder_names[i] for i in sorted_indices]\n",
    "x_values = [x_values[i] for i in sorted_indices]\n",
    "print(folder_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "21fd83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "All writers have both same_text=1 and same_text=0.\n",
      "All writers have both isEng=1 and isEng=0.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each directory and collect image file paths for labeled images only\n",
    "image_dirs = [os.path.join(image_PATH, folder) for folder in folder_names]\n",
    "writers = []\n",
    "isEng = []\n",
    "same_text = []\n",
    "file_names = []\n",
    "\n",
    "for image_dir in image_dirs:\n",
    "    for f in os.listdir(image_dir):\n",
    "        if f.endswith('.jpg'):\n",
    "            base_name = os.path.splitext(f)[0]  # Remove extension\n",
    "            parts = base_name.split('_')\n",
    "\n",
    "            if len(parts) != 2:\n",
    "                continue  # Skip files that don't follow the expected pattern\n",
    "\n",
    "            index, version = parts\n",
    "\n",
    "            if int(version)>2:\n",
    "                isEng.append(1)\n",
    "            else:\n",
    "                isEng.append(0)\n",
    "            if int(version)%2==0:\n",
    "                same_text.append(1)\n",
    "            else:\n",
    "                same_text.append(0)\n",
    "            file_names.append(os.path.join(image_dir,f))\n",
    "            writers.append(int(index))\n",
    "\n",
    "# Create a dataframe from the extracted index and version values\n",
    "train_file_df = pd.DataFrame({'writer': writers, 'isEng': isEng, 'same_text': same_text,'file_name':file_names})\n",
    "\n",
    "# Display the dataframe\n",
    "print(train_file_df['writer'].nunique())\n",
    "\n",
    "'''print(train_file_df['writer'].min())\n",
    "print(train_file_df['writer'].max())\n",
    "# Check which writer values are missing in the interval 1-300\n",
    "all_writers = set(range(1, 301))\n",
    "present_writers = set(train_file_df['writer'].unique())\n",
    "missing_writers = all_writers - present_writers\n",
    "\n",
    "print(f\"Missing writers in the interval 1-300: {sorted(missing_writers)}\")'''\n",
    "\n",
    "check_if_both(train_file_df,column_name='same_text')\n",
    "check_if_both(train_file_df, column_name='isEng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b053d8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each unique writer value occurs on exactly 4 rows.\n"
     ]
    }
   ],
   "source": [
    "check_occurrences(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "893e76a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train  \\\n",
       "0       1          0      0      1   \n",
       "1       1          1      0      1   \n",
       "2       1          0      1      1   \n",
       "3       1          1      1      1   \n",
       "4       2          0      0      1   \n",
       "5       2          1      0      1   \n",
       "6       2          0      1      1   \n",
       "7       2          1      1      1   \n",
       "8       3          0      0      1   \n",
       "9       3          1      0      1   \n",
       "\n",
       "                                           file_name  \n",
       "0  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "1  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "2  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "3  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "4  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "5  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "6  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "7  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "8  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  \n",
       "9  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the file_name column to the train_df dataframe based on the writer column\n",
    "train_df = train_df.merge(train_file_df, on=['isEng','writer','same_text'], how='left')\n",
    "\n",
    "# Display the updated dataframe\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2dc3b35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\251_300\\0262_3.jpg\n",
      "262 1 0\n",
      "-------------\n",
      "1018\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\251_300\\0255_3.jpg\n",
      "255 1 0\n",
      "-------------\n",
      "953\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\201_250\\0239_2.jpg\n",
      "239 0 1\n",
      "-------------\n",
      "266\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\51_100\\0067_3.jpg\n",
      "67 1 0\n",
      "-------------\n",
      "445\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\101_150\\0112_2.jpg\n",
      "112 0 1\n",
      "-------------\n",
      "47\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\1_50\\0012_4.jpg\n",
      "12 1 1\n",
      "-------------\n",
      "132\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\1_50\\0034_1.jpg\n",
      "34 0 0\n",
      "-------------\n",
      "928\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\201_250\\0233_1.jpg\n",
      "233 0 0\n",
      "-------------\n",
      "634\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\151_200\\0159_3.jpg\n",
      "159 1 0\n",
      "-------------\n",
      "669\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\151_200\\0168_2.jpg\n",
      "168 0 1\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "check_title_association(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f2c1f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train  \\\n",
       "0       1          0      0      1   \n",
       "1       1          1      0      1   \n",
       "2       1          0      1      1   \n",
       "3       1          1      1      1   \n",
       "4       2          0      0      1   \n",
       "5       2          1      0      1   \n",
       "6       2          0      1      1   \n",
       "7       2          1      1      1   \n",
       "8       3          0      0      1   \n",
       "9       3          1      0      1   \n",
       "\n",
       "                                           file_name  male  \n",
       "0  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "1  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "2  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "3  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "4  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "5  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "6  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "7  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "8  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  \n",
       "9  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(sex_df, on=['writer'], how='left')\n",
    "\n",
    "# Display the updated dataframe\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d01c8d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train  \\\n",
       "0       1          0      0      1   \n",
       "1       1          1      0      1   \n",
       "2       1          0      1      1   \n",
       "3       1          1      1      1   \n",
       "4       2          0      0      1   \n",
       "5       2          1      0      1   \n",
       "6       2          0      1      1   \n",
       "7       2          1      1      1   \n",
       "8       3          0      0      1   \n",
       "9       3          1      0      1   \n",
       "\n",
       "                                           file_name  male  index  \n",
       "0  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      0  \n",
       "1  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      1  \n",
       "2  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      2  \n",
       "3  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      3  \n",
       "4  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      4  \n",
       "5  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      5  \n",
       "6  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      6  \n",
       "7  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      7  \n",
       "8  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      8  \n",
       "9  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0      9  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['index'] = train_df.index\n",
    "\n",
    "# Display the updated dataframe\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "011c8eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "     writer  male\n",
      "576     145     1\n",
      "577     145     1\n",
      "578     145     1\n",
      "579     145     1\n",
      "     writer  male\n",
      "144     145     1\n",
      "-------------\n",
      "18\n",
      "    writer  male\n",
      "68      18     0\n",
      "69      18     0\n",
      "70      18     0\n",
      "71      18     0\n",
      "    writer  male\n",
      "17      18     0\n",
      "-------------\n",
      "26\n",
      "     writer  male\n",
      "100      26     1\n",
      "101      26     1\n",
      "102      26     1\n",
      "103      26     1\n",
      "    writer  male\n",
      "25      26     1\n",
      "-------------\n",
      "123\n",
      "     writer  male\n",
      "488     123     1\n",
      "489     123     1\n",
      "490     123     1\n",
      "491     123     1\n",
      "     writer  male\n",
      "122     123     1\n",
      "-------------\n",
      "260\n",
      "      writer  male\n",
      "1036     260     1\n",
      "1037     260     1\n",
      "1038     260     1\n",
      "1039     260     1\n",
      "     writer  male\n",
      "259     260     1\n",
      "-------------\n",
      "248\n",
      "     writer  male\n",
      "988     248     0\n",
      "989     248     0\n",
      "990     248     0\n",
      "991     248     0\n",
      "     writer  male\n",
      "247     248     0\n",
      "-------------\n",
      "206\n",
      "     writer  male\n",
      "820     206     1\n",
      "821     206     1\n",
      "822     206     1\n",
      "823     206     1\n",
      "     writer  male\n",
      "205     206     1\n",
      "-------------\n",
      "74\n",
      "     writer  male\n",
      "292      74     0\n",
      "293      74     0\n",
      "294      74     0\n",
      "295      74     0\n",
      "    writer  male\n",
      "73      74     0\n",
      "-------------\n",
      "231\n",
      "     writer  male\n",
      "920     231     0\n",
      "921     231     0\n",
      "922     231     0\n",
      "923     231     0\n",
      "     writer  male\n",
      "230     231     0\n",
      "-------------\n",
      "144\n",
      "     writer  male\n",
      "572     144     0\n",
      "573     144     0\n",
      "574     144     0\n",
      "575     144     0\n",
      "     writer  male\n",
      "143     144     0\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "check_sex_association(train_df,sex_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "58718a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\151_200\\0161_3.jpg\n",
      "161 1 0\n",
      "-------------\n",
      "369\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\51_100\\0093_2.jpg\n",
      "93 0 1\n",
      "-------------\n",
      "860\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\201_250\\0216_1.jpg\n",
      "216 0 0\n",
      "-------------\n",
      "418\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\101_150\\0105_3.jpg\n",
      "105 1 0\n",
      "-------------\n",
      "226\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\51_100\\0057_3.jpg\n",
      "57 1 0\n",
      "-------------\n",
      "29\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\1_50\\0008_2.jpg\n",
      "8 0 1\n",
      "-------------\n",
      "1055\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\251_300\\0264_4.jpg\n",
      "264 1 1\n",
      "-------------\n",
      "1097\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\251_300\\0275_2.jpg\n",
      "275 0 1\n",
      "-------------\n",
      "605\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\151_200\\0152_2.jpg\n",
      "152 0 1\n",
      "-------------\n",
      "545\n",
      "D:\\download\\PD project\\datasets\\ICDAR 2013 - Gender Identification Competition Dataset\\unzipped\\101_150\\0137_2.jpg\n",
      "137 0 1\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "check_title_association(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "15a5bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times 'male' is 0: 572\n",
      "Number of times 'male' is 1: 556\n",
      "Number of times 'male' is something else: 0\n",
      "All writers have both same_text=1 and same_text=0.\n",
      "All writers have both isEng=1 and isEng=0.\n",
      "Number of rows where train == 1: 1012\n",
      "Fraction of rows where train == 1: 0.90\n",
      "The train column is constant for all writers.\n",
      "Each unique writer value occurs on exactly 4 rows.\n"
     ]
    }
   ],
   "source": [
    "male_counts(train_df)\n",
    "check_if_both(train_df, column_name='same_text')\n",
    "check_if_both(train_df, column_name='isEng') \n",
    "check_randomization(train_df)\n",
    "check_grouping(train_df)\n",
    "check_occurrences(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d2dd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_base_metadata(filepath):\n",
    "    stats = os.stat(filepath)\n",
    "    return {\n",
    "        \"full_path\": os.path.abspath(filepath),\n",
    "        \"size_bytes\": stats.st_size,\n",
    "        \"created\": datetime.fromtimestamp(stats.st_ctime).isoformat(),\n",
    "        \"modified\": datetime.fromtimestamp(stats.st_mtime).isoformat(),\n",
    "        \"accessed\": datetime.fromtimestamp(stats.st_atime).isoformat()\n",
    "    }\n",
    "\n",
    "def load_log(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_log(data, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def add_or_update_file(filepath, log_path, custom_metadata=None):\n",
    "    \"\"\"\n",
    "    Adds or updates a file's metadata entry, including custom metadata.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    log = load_log(log_path)\n",
    "\n",
    "    base_meta = get_base_metadata(filepath)\n",
    "    entry = log.get(filename, {})\n",
    "\n",
    "    # Combine existing metadata, new base, and new custom metadata\n",
    "    entry.update(base_meta)\n",
    "    if custom_metadata:\n",
    "        entry.update(custom_metadata)\n",
    "\n",
    "    log[filename] = entry\n",
    "    save_log(log, log_path)\n",
    "    print(f\"Updated log for {filename}\")\n",
    "\n",
    "def read_metadata(filepath, log_path):\n",
    "    \"\"\"\n",
    "    Adds or updates a file's metadata entry, including custom metadata.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    log = load_log(log_path)\n",
    "\n",
    "    entry = log.get(filename, None)\n",
    "    if entry:\n",
    "        print(f\"Metadata for {filename}:\")\n",
    "        for key, value in entry.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"No metadata found for {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b418559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved to D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\preprocessed_data\\icdar_train_df_20250514_165047.csv\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = os.path.join(source_path, \"outputs\", \"preprocessed_data\")\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "output_file = os.path.join(output_dir, f\"icdar_train_df_{timestamp}.csv\")\n",
    "train_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Dataframe saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "165d85c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m LOG_FILE \u001b[38;5;241m=\u001b[39m output_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfile_metadata_log.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43madd_or_update_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43mdataframe with the following columns: writer, language, same_text, isEng, train, filename, index; \u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43m        Each row is one of the original dataset image files. This is the first version in which I have checked every operation done on the dataframe.\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[112], line 32\u001b[0m, in \u001b[0;36madd_or_update_file\u001b[1;34m(filepath, log_path, custom_metadata)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     31\u001b[0m filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(filepath)\n\u001b[1;32m---> 32\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[43mload_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m base_meta \u001b[38;5;241m=\u001b[39m get_base_metadata(filepath)\n\u001b[0;32m     35\u001b[0m entry \u001b[38;5;241m=\u001b[39m log\u001b[38;5;241m.\u001b[39mget(filename, {})\n",
      "Cell \u001b[1;32mIn[112], line 16\u001b[0m, in \u001b[0;36mload_log\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "File \u001b[1;32md:\\burtm\\Visual_studio_code\\conda_environments\\GeneralPurposeML\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\burtm\\Visual_studio_code\\conda_environments\\GeneralPurposeML\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32md:\\burtm\\Visual_studio_code\\conda_environments\\GeneralPurposeML\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32md:\\burtm\\Visual_studio_code\\conda_environments\\GeneralPurposeML\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "LOG_FILE = output_dir+\"\\\\file_metadata_log.json\"\n",
    "add_or_update_file(\n",
    "    output_file, LOG_FILE,\n",
    "    custom_metadata={\n",
    "        \"seed\": seed,\n",
    "        \"description\": '''dataframe with the following columns: writer, language, same_text, isEng, train, filename, index; \n",
    "        Each row is one of the original dataset image files. This is the first version in which I have checked every operation done on the dataframe.''' \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_metadata(\n",
    "    output_file,\n",
    "    log_path=LOG_FILE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
