{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\burtm\\Visual_studio_code\\conda_environments\\GeneralPurposeML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(\"D:\\\\burtm\\\\Visual_studio_code\\\\PD_related_projects\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2add41",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = 'trocr-small-stage1'\n",
    "\n",
    "transform = utils_transforms.get_transform(selected_model)\n",
    "#devo riscrivere la funzione get_model in maniera piu' ordinata e testare gli output dopo aver selezionato un modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4494fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "N_max=282\n",
    "patches=True\n",
    "input_filename='icdar_train_df_patches_20250514_221029.csv'\n",
    "huggingface=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b85963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is: \",device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path=\"D:\\\\burtm\\\\Visual_studio_code\\\\PD_related_projects\"\n",
    "train_df = pd.read_csv(f\"{source_path}\\\\outputs\\\\preprocessed_data\\\\{input_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "compute_output(model, transform, train_df.iloc[i], huggingface, patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5d140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I test the output of the model\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images, out of 5640\n",
      "Processed 100 images, out of 5640\n",
      "Processed 200 images, out of 5640\n",
      "Processed 300 images, out of 5640\n",
      "Processed 400 images, out of 5640\n",
      "Processed 500 images, out of 5640\n",
      "Processed 600 images, out of 5640\n",
      "Processed 700 images, out of 5640\n",
      "Processed 800 images, out of 5640\n",
      "Processed 900 images, out of 5640\n",
      "Processed 1000 images, out of 5640\n",
      "Processed 1100 images, out of 5640\n",
      "Processed 1200 images, out of 5640\n",
      "Processed 1300 images, out of 5640\n",
      "Processed 1400 images, out of 5640\n",
      "Processed 1500 images, out of 5640\n",
      "Processed 1600 images, out of 5640\n",
      "Processed 1700 images, out of 5640\n",
      "Processed 1800 images, out of 5640\n",
      "Processed 1900 images, out of 5640\n",
      "Processed 2000 images, out of 5640\n",
      "Processed 2100 images, out of 5640\n",
      "Processed 2200 images, out of 5640\n",
      "Processed 2300 images, out of 5640\n",
      "Processed 2400 images, out of 5640\n",
      "Processed 2500 images, out of 5640\n",
      "Processed 2600 images, out of 5640\n",
      "Processed 2700 images, out of 5640\n",
      "Processed 2800 images, out of 5640\n",
      "Processed 2900 images, out of 5640\n",
      "Processed 3000 images, out of 5640\n",
      "Processed 3100 images, out of 5640\n",
      "Processed 3200 images, out of 5640\n",
      "Processed 3300 images, out of 5640\n",
      "Processed 3400 images, out of 5640\n",
      "Processed 3500 images, out of 5640\n",
      "Processed 3600 images, out of 5640\n",
      "Processed 3700 images, out of 5640\n",
      "Processed 3800 images, out of 5640\n",
      "Processed 3900 images, out of 5640\n",
      "Processed 4000 images, out of 5640\n",
      "Processed 4100 images, out of 5640\n",
      "Processed 4200 images, out of 5640\n",
      "Processed 4300 images, out of 5640\n",
      "Processed 4400 images, out of 5640\n",
      "Processed 4500 images, out of 5640\n",
      "Processed 4600 images, out of 5640\n",
      "Processed 4700 images, out of 5640\n",
      "Processed 4800 images, out of 5640\n",
      "Processed 4900 images, out of 5640\n",
      "Processed 5000 images, out of 5640\n",
      "Processed 5100 images, out of 5640\n",
      "Processed 5200 images, out of 5640\n",
      "Processed 5300 images, out of 5640\n",
      "Processed 5400 images, out of 5640\n",
      "Processed 5500 images, out of 5640\n",
      "Processed 5600 images, out of 5640\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Initialize a dictionary to store new feature columns\n",
    "new_features = {}\n",
    "\n",
    "for index,t in train_df.iterrows():\n",
    "    for i, value in enumerate(output.squeeze().tolist()):\n",
    "        column_name = f\"f{i+1}\"\n",
    "        if column_name not in new_features:\n",
    "            new_features[column_name] = []\n",
    "        new_features[column_name].append(value)\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Processed {index} images, out of {len(train_df)}\")\n",
    "\n",
    "    \n",
    "# Add the new features to the DataFrame in one operation\n",
    "new_features_df = pd.DataFrame(new_features)\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), new_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11439c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 images, out of 5640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''from utils.dataframes import CustomImageDataset, CustomPatchDataset\n",
    "from torch.utils.data import Dataset,DataLoader, random_split\n",
    "source_path=\"D:\\\\burtm\\\\Visual_studio_code\\\\PD_related_projects\"\n",
    "train_df = pd.read_csv(f\"{source_path}\\\\outputs\\\\preprocessed_data\\\\{input_filename}\")\n",
    "model.eval()\n",
    "dataset = CustomPatchDataset(train_df[train_df['writer']<=N_max] ,\n",
    "                                        label_column='male', transform=transform, huggingface=huggingface)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "new_features = {}\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    patch = batch['image'].to(device)\n",
    "    output = model(pixel_values=patch)\n",
    "    cls_token_output = output.last_hidden_state[:, 0, :]  # Extract the CLS token\n",
    "    for i, value in enumerate(cls_token_output.squeeze().tolist()):\n",
    "        column_name = f\"f{i+1}\"\n",
    "        if column_name not in new_features:\n",
    "            new_features[column_name] = []\n",
    "        new_features[column_name].append(value)\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"Processed {idx * batch_size} images, out of {len(dataset)}\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_features_df = pd.DataFrame(new_features)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1a3b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writer</th>\n",
       "      <th>same_text</th>\n",
       "      <th>isEng</th>\n",
       "      <th>train</th>\n",
       "      <th>file_name</th>\n",
       "      <th>male</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>...</th>\n",
       "      <th>f375</th>\n",
       "      <th>f376</th>\n",
       "      <th>f377</th>\n",
       "      <th>f378</th>\n",
       "      <th>f379</th>\n",
       "      <th>f380</th>\n",
       "      <th>f381</th>\n",
       "      <th>f382</th>\n",
       "      <th>f383</th>\n",
       "      <th>f384</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>1</td>\n",
       "      <td>988</td>\n",
       "      <td>494</td>\n",
       "      <td>1482</td>\n",
       "      <td>988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922357</td>\n",
       "      <td>2.522360</td>\n",
       "      <td>4.304227</td>\n",
       "      <td>-3.425128</td>\n",
       "      <td>3.495620</td>\n",
       "      <td>-4.153519</td>\n",
       "      <td>-0.852054</td>\n",
       "      <td>-1.164748</td>\n",
       "      <td>-2.234782</td>\n",
       "      <td>-2.404248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "      <td>495</td>\n",
       "      <td>1485</td>\n",
       "      <td>990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485612</td>\n",
       "      <td>1.888572</td>\n",
       "      <td>4.129086</td>\n",
       "      <td>-3.297427</td>\n",
       "      <td>4.332079</td>\n",
       "      <td>-4.687369</td>\n",
       "      <td>-2.287635</td>\n",
       "      <td>-1.905988</td>\n",
       "      <td>-4.285491</td>\n",
       "      <td>-1.362528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>1</td>\n",
       "      <td>494</td>\n",
       "      <td>1976</td>\n",
       "      <td>988</td>\n",
       "      <td>2470</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.275970</td>\n",
       "      <td>1.497854</td>\n",
       "      <td>3.086382</td>\n",
       "      <td>-2.358793</td>\n",
       "      <td>4.704427</td>\n",
       "      <td>-5.747137</td>\n",
       "      <td>-3.386876</td>\n",
       "      <td>1.461058</td>\n",
       "      <td>-3.862585</td>\n",
       "      <td>-1.632300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>1</td>\n",
       "      <td>494</td>\n",
       "      <td>494</td>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.605459</td>\n",
       "      <td>2.483239</td>\n",
       "      <td>4.245601</td>\n",
       "      <td>-3.242137</td>\n",
       "      <td>3.766826</td>\n",
       "      <td>-4.104949</td>\n",
       "      <td>-1.693988</td>\n",
       "      <td>-1.805966</td>\n",
       "      <td>-2.415438</td>\n",
       "      <td>-1.441694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>0</td>\n",
       "      <td>1482</td>\n",
       "      <td>494</td>\n",
       "      <td>1976</td>\n",
       "      <td>988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307438</td>\n",
       "      <td>1.057468</td>\n",
       "      <td>2.697207</td>\n",
       "      <td>-1.516698</td>\n",
       "      <td>3.344037</td>\n",
       "      <td>-4.181660</td>\n",
       "      <td>-2.132452</td>\n",
       "      <td>-1.470941</td>\n",
       "      <td>-4.696310</td>\n",
       "      <td>-0.665148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   writer  same_text  isEng  train  \\\n",
       "0     190          0      0      1   \n",
       "1      24          0      1      1   \n",
       "2      26          1      1      1   \n",
       "3     190          0      0      1   \n",
       "4     160          0      1      1   \n",
       "\n",
       "                                           file_name  male     x     y    x2  \\\n",
       "0  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     1   988   494  1482   \n",
       "1  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0   990   495  1485   \n",
       "2  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     1   494  1976   988   \n",
       "3  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     1   494   494   988   \n",
       "4  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...     0  1482   494  1976   \n",
       "\n",
       "     y2  ...      f375      f376      f377      f378      f379      f380  \\\n",
       "0   988  ... -0.922357  2.522360  4.304227 -3.425128  3.495620 -4.153519   \n",
       "1   990  ... -0.485612  1.888572  4.129086 -3.297427  4.332079 -4.687369   \n",
       "2  2470  ... -1.275970  1.497854  3.086382 -2.358793  4.704427 -5.747137   \n",
       "3   988  ... -1.605459  2.483239  4.245601 -3.242137  3.766826 -4.104949   \n",
       "4   988  ... -0.307438  1.057468  2.697207 -1.516698  3.344037 -4.181660   \n",
       "\n",
       "       f381      f382      f383      f384  \n",
       "0 -0.852054 -1.164748 -2.234782 -2.404248  \n",
       "1 -2.287635 -1.905988 -4.285491 -1.362528  \n",
       "2 -3.386876  1.461058 -3.862585 -1.632300  \n",
       "3 -1.693988 -1.805966 -2.415438 -1.441694  \n",
       "4 -2.132452 -1.470941 -4.696310 -0.665148  \n",
       "\n",
       "[5 rows x 395 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd41e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\preprocessed_data\\icdar_EXTRACTED_trocr_stage_1_10blocks_20250509_153553.csv\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_path=source_path+f\"\\\\outputs\\\\preprocessed_data\\\\icdar_EXTRACTED_trocr_stage_1_10blocks_{timestamp}.csv\"\n",
    "train_df.to_csv(file_path, index=False)\n",
    "print(f\"File saved: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2dfb57",
   "metadata": {},
   "source": [
    "# easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e39392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.data_loading as data_loading\n",
    "    import utils.visualization as visualization\n",
    "    import utils.dataframes as dataframes\n",
    "    import utils.utils_transforms as u_transforms\n",
    "    import utils.training_utils as training_utils\n",
    "    import utils.model_utils as model_utils\n",
    "    \n",
    "\n",
    "    importlib.reload(data_loading)\n",
    "    importlib.reload(visualization)\n",
    "    importlib.reload(dataframes)\n",
    "    importlib.reload(u_transforms)\n",
    "    importlib.reload(model_utils)\n",
    "    importlib.reload(training_utils)\n",
    "\n",
    "    return data_loading, visualization, dataframes, u_transforms, training_utils, model_utils\n",
    "data_loading, visualization, dataframes, u_transforms, training_utils, model_utils = reload_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output(model, transform, t, huggingface, patches):\n",
    "    image_file = t['file_name']\n",
    "    image = Image.open(image_file).convert(\"RGB\")\n",
    "    if patches:\n",
    "        x1 = t['x']\n",
    "        y1 = t['y']\n",
    "        x2 = t['x2']\n",
    "        y2 = t['y2']\n",
    "        patch = image.crop((x1, y1, x2, y2))\n",
    "    else:\n",
    "        patch = image.copy()\n",
    "    if huggingface:\n",
    "        # the transform is actually an huggingface processor in this case\n",
    "        inputs = transform(images=patch, return_tensors=\"pt\")\n",
    "        # Remove batch dimension from inputs\n",
    "        patch = inputs['pixel_values'].squeeze()\n",
    "    else:\n",
    "        patch = transform(patch)\n",
    "    patch = patch.to(device)\n",
    "    output = model(patch.unsqueeze(0))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdbc167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(transform, t, huggingface, patches):\n",
    "    image_file = t['file_name']\n",
    "    image = Image.open(image_file).convert(\"RGB\")\n",
    "    if patches:\n",
    "        x1 = t['x']\n",
    "        y1 = t['y']\n",
    "        x2 = t['x2']\n",
    "        y2 = t['y2']\n",
    "        patch = image.crop((x1, y1, x2, y2))\n",
    "    else:\n",
    "        patch = image.copy()\n",
    "\n",
    "    # Show original image/patch\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(patch)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if huggingface:\n",
    "        inputs = transform(images=patch, return_tensors=\"pt\")\n",
    "        transformed_patch = inputs['pixel_values'].squeeze()\n",
    "        # Convert tensor to numpy for visualization\n",
    "    else:\n",
    "        transformed_patch = transform(patch)\n",
    "    \n",
    "    img_np = transformed_patch.permute(1, 2, 0).cpu().numpy()\n",
    "    # Normalize if needed\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Transformed\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
