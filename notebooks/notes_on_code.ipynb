{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8338319d",
   "metadata": {},
   "source": [
    "# train_df_icdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e3e80",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "OFFICIAL RELEASE: icdar_train_df_20250514_175905.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bdac5",
   "metadata": {},
   "source": [
    "Code explanation: prendo i filenames ed estraggo same_text, writer e isEng. Creo un dataframe da questi che contiene anche il percorso del file.\n",
    "Faccio il merge su writer con il dataframe da train_answers che ha writer e male come colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0711da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Setto un seed -> i risultati dovrebbero essere sempre gli stessi quando seleziono train e val ->\n",
    "ho verificato che se lancio due volte in momenti diversi ottengo la stessa lista di writers in validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb60689",
   "metadata": {},
   "source": [
    "X\n",
    "sto prendendo writer, isEng etc dal nome del file e sto associando con le labels\n",
    "prendo le labels da train_answers.csv\n",
    "\n",
    "Problema: potrebbe essere che train_answers e train abbiano gli stessi scrittori  (handcrafted features da train è associato correttamente alle labels) \n",
    "ma che train_answers e i filenames delle immagini non seguano lo stesso ordinamento degli scrittori?\n",
    "Come posso verificare che sto associando le immagini corrette?\n",
    "Posso addestrare un modello che usi cnn. Se efficace non ci dovrebbero essere errori\n",
    "posso fare un modello che matcha immagini e features\n",
    "controllo da dove sono scaricati i dati\n",
    "posso riestrarre le features e compararle con quelle già estratte\n",
    "\n",
    "problema: potrebeb essere che train answers e train abbiano scrittori ordinati diversamente? Improbabile perchè sono tutti e due dataset di kaggle e FE funziona bene (80% val accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f5309",
   "metadata": {},
   "source": [
    "train_answers \n",
    "\n",
    "contiene 282 scrittori.\n",
    "Number of times 'male' is 0: 143\n",
    "Number of times 'male' is 1: 139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac1003",
   "metadata": {},
   "source": [
    "Dati estratti dai filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fab613",
   "metadata": {},
   "source": [
    "I load the images from the following folders: ['1_50', '51_100', '101_150', '151_200', '201_250', '251_300']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa9313",
   "metadata": {},
   "source": [
    "Costruzione del df da file:\n",
    "Ho controllato che l'associazione con isEng sia corretta: pg 1 e 2 per uno scrittore sono in arabo, pg 3 e 4 in inglese\n",
    "\n",
    "Come verificare se sto prendendo il valore giusto? Posso guardare degli esempi: \n",
    "-per writer=1 i primi due sono arabi isEng=0 e i secondi due sono inglesi isEng=1. Per writer 1 e writer 2 v=4 ha lo stesso testo mentre v=3 ha testo diverso. Per l'arabo v=2 hanno testo uguale (mi sembra) mentre v=1 ha testo diverso\n",
    "-lo stesso vale per writer 253 e 254\n",
    "-> sono ragionevolmente sicuro che sia tutto a posto\n",
    "\n",
    "- Devo verificare che sto associando i percorsi giusti (che effettivamente nel df che creo writer e same_page siano costruiti nel modo giusto dal filename)\n",
    "-> guardo il nome dei file e vedo se le colonne corrispondenti (writer, isEng etc ..) hanno il valore corretto. \n",
    "Ho controllato per 10 righe prese a caso e l'associazione è corretta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537309de",
   "metadata": {},
   "source": [
    "Ho aggiunto la colonna train\n",
    "I need to check that 90% of writers is with train=1 -> the fractionof row with train=1 is exactly 90%\n",
    "I need to check that a writer is only in one group -> i counted the unique values for each group of rows that share a writer. I have always one unique value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399d557",
   "metadata": {},
   "source": [
    "Associating with the sex_df (adding the sex column)\n",
    "- to confirm that the merging is working i randomly sample rows from sex_df and train_df and check that the writer and sex columns are shared -> confirmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153512ec",
   "metadata": {},
   "source": [
    "Test di verifica sul dataset finale ->\n",
    "Number of times 'male' is 0: 572\n",
    "Number of times 'male' is 1: 556\n",
    "Number of times 'male' is something else: 0\n",
    "All writers have both same_text=1 and same_text=0.\n",
    "All writers have both isEng=1 and isEng=0.\n",
    "Number of rows where train == 1: 1012\n",
    "Fraction of rows where train == 1: 0.90\n",
    "The train column is constant for all writers.\n",
    "Each unique writer value occurs on exactly 4 rows.\n",
    "\n",
    "I checked that there are no missing values:\n",
    "All writers have both same_text=1 and same_text=0.\n",
    "All writers have both isEng=1 and isEng=0.\n",
    "\n",
    "ho verificato di avere 4 esempi per ogni scrittore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f0f76",
   "metadata": {},
   "source": [
    "Prima di lanciare il codice ho fatto push su github\n",
    "Salvo con seed e descrizione del dataset in un log file di tipo json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d210aa3",
   "metadata": {},
   "source": [
    "# train_df_icdar_FE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077fd1b4",
   "metadata": {},
   "source": [
    "OFFICIAL RELEASE: icdar_train_df_KAGGLE_20250514_181737.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb330a",
   "metadata": {},
   "source": [
    "Costruisce il df che posso usare per addestrare i modelli che usano le features di kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c548097",
   "metadata": {},
   "source": [
    "Semplicemente fa il merging tra il train e il train_answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9d5a2",
   "metadata": {},
   "source": [
    "# feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a9b72",
   "metadata": {},
   "source": [
    "RESULTS:\n",
    "the validation accuracy I obtain by simply applying gbm to the kaggle features is 75% (100% on training). \n",
    "the validation on isEng is 98% -> task is much easier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5a544",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "In this code I load the dataset generated by train_df_icdar_FE and apply without preprocessing some models like xgb etc .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddddfa",
   "metadata": {},
   "source": [
    "I simply need to check that the dataset has non nans, missing values etc .. -> checked and is allright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82ffba",
   "metadata": {},
   "source": [
    "# patches_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366ded7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "OFFICIAL RELEASE: icdar_train_df_patches_20250515_164130.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff5f26",
   "metadata": {},
   "source": [
    "Carico il file generato da train_df_icdar. Per ogni documento singolo genero delle patches. Genero un nuovo dataframe identico a quello di partenza ma con \n",
    "le colonne x,y,x2,y2 per identificare le patches, assegno un valore univoco alle patches per further reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9467bbc",
   "metadata": {},
   "source": [
    "NOT OPTIMAL\n",
    "Devo verificare che le patches estratte abbiano senso -> tutte contengono testo ma alcune hanno il campo di vista mezzo vuoto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a6567",
   "metadata": {},
   "source": [
    "Devo verificare che ho 5 patch per ogni coppia isEng, same_page fissato lo scrittore\n",
    "Dato che ogni coppia è associata a un indice unico controllo che per ogni indice ho 5 patches -> ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daebd3",
   "metadata": {},
   "source": [
    "Devo verificare che le nuove patches create mantengano l'associazione con la label e gli altri parametri del df di input\n",
    "-> estraggo delle righe a caso dal df esteso e vado a confrontare con le righe del writer corrispondente nel df originale\n",
    "\n",
    "vedo che la riga i-esima che corrisponde ad una patch ha writer=n, male=m e train=t.\n",
    "Le righe in train_df per writer=n hanno lo stesso m e t -> ragionevolmente sicuro che l'assoicazione è stata \n",
    "fatta correttamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8dc7a8",
   "metadata": {},
   "source": [
    "Devo verificare di avere 5 patches per ogni immagine di partenza -> verifico che ogni writer appaia 5*4 volte, che abbia sempre lo stesso valore di male ->ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0573e",
   "metadata": {},
   "source": [
    "# deepfeatureextraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8002f",
   "metadata": {},
   "source": [
    "OFFICIAL RELEASE:\n",
    "trocr-small-stage1 (cls token only): icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv\n",
    "trocr-small-stage1 (pooling): \n",
    "resnet50 (base transform): icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv\n",
    "resnet50 (custom transform):  icdar_EXTRACTED_train_df_resnet50_20250516_163737.csv\n",
    "trocr-small-handwritten (cls token): icdar_EXTRACTED_train_df_trocr-small-handwritten_20250516_150814.csv\n",
    "vit: icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv\n",
    "trocr-base-handwritten: icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv\n",
    "trocr-large-handwritten: icdar_EXTRACTED_train_df_trocr-large-handwritten_20250517_150651.csv\n",
    "trocr-large-stage1:\n",
    "clip-vit: icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0fea2",
   "metadata": {},
   "source": [
    "This code takes a deep learning model and a dataframe with filenames (possibly with regions to crop)\n",
    "For each row extracts the image from the filename, apply the model, returns the extracted features and appends them to the row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c22142",
   "metadata": {},
   "source": [
    "I'll need to check that the feature extractors work as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeffaf17",
   "metadata": {},
   "source": [
    "## Does the resnet work as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60964baa",
   "metadata": {},
   "source": [
    "## Does the trocr-small-stage1 work as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a99cd",
   "metadata": {},
   "source": [
    "When I load it it returns this: ''Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight'] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a874ea",
   "metadata": {},
   "source": [
    "what if i apply to data similar to its training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c37244",
   "metadata": {},
   "source": [
    "If i take model.encoder and use it for inference it returns me an output that has lasr_hidden_state and pooler_output as outputs\n",
    "I cannot rely on the pooler output because the weights are not initialized \n",
    "\n",
    "If i subclass the model with: class FullClassifier(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(FullClassifier, self).__init__()\n",
    "        self.encoder = encoder.encoder\n",
    "        self.embeddings = encoder.embeddings\n",
    "        self.layernorm = encoder.layernorm\n",
    "    def forward(self, x):\n",
    "        hidden_state = self.embeddings(x)\n",
    "        hidden_state= self.encoder(hidden_state).last_hidden_state\n",
    "        hidden_state = self.layernorm(hidden_state)\n",
    "        return hidden_state\n",
    "I get the same output as the original model (if i take hidden_layers) -> in inference the last layer is the layernorm and subclassing is ok for inference\n",
    "\n",
    "I have doubts that defining a new model in this way may cause problems in the gradient propagation -> since it is difficult to check I'll avoid subclassing as much as possible -> for sure i will use the base model for feature extraction\n",
    "\n",
    "If i wrap the model with huggingface wrapper the output remains the same and it seems very unlikely to cause problems in the flow of gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602aba1c",
   "metadata": {},
   "source": [
    "## Does the trocr-small-handwriting work as expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72c271",
   "metadata": {},
   "source": [
    "I get the following warning: Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1c542",
   "metadata": {},
   "source": [
    "PROBLEM\n",
    "I've done one test on the word-segmentation script. The word is correctly identified as \"migration\" (the problem was not the pooler since the same warning appeared)\n",
    "If i feed an iam-lines example it works correctly. The processed image is VERY squeezed \n",
    "I am not sure if the most important factor for good recognition is the x,y ratio or the color distribution of the image -> I should select a bunch of crops with different ratios, transformations etc and compare the performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3ac0b",
   "metadata": {},
   "source": [
    "PROBLEM\n",
    "Chatgpt suggested the model outputs are different during inference and training: the model architecture i have when i print is the standard vision encoder decoder. trocr doesn't use the weights of the pooler in its inference even if they are in the architecture -> the architecture doesn't represent the forward method\n",
    "I am checking this via printing hooks during inference. The hooks show that the pooler is not part of the inference (last layer is a layernorm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f4ab34",
   "metadata": {},
   "source": [
    "## vit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c64da",
   "metadata": {},
   "source": [
    "\n",
    "vit-base-patch16-224 : is pretrained on whole imagenet and fine tuned on old imagenet\n",
    "\n",
    "vit-base-patch16-224-in21k: is pretrained but not finetuned\n",
    "I can use the same checkpoint to load the model as it is or for image classification. If I load it for image classification the pooling layer is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ddfdc5",
   "metadata": {},
   "source": [
    "## trocr-base and large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d337eaa",
   "metadata": {},
   "source": [
    "It takes almost 30min to upload the zipped files to colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4241c",
   "metadata": {},
   "source": [
    "I have loaded the model using colab notebooks since my pc has too little ram to keep the model, even if compressed\n",
    "The inference takes much less 9min instead of 30mins on my pc! (to build the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073aef1f",
   "metadata": {},
   "source": [
    "If i compare the number of patches that come out of the embedding layer and the number of patches in output i have 576 vs 577 -> it seems there is no distillation token (probably because it is the fine tuned version -> the distillation token is not used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede9e56",
   "metadata": {},
   "source": [
    "## clip-vit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a58fc6",
   "metadata": {},
   "source": [
    "# classifier on extracted features (mlp on feature extractor notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e8152",
   "metadata": {},
   "source": [
    "Using gbm as classifier i get the following results (gender problem)\n",
    "-transformers\n",
    "-imagenet pretrained\n",
    "vit-base-patch16-in21k: 67% val, 85% train \n",
    "clip-vit: 64%, 87%\n",
    "-text pretrained\n",
    "small-stage1: 60%, 80%\n",
    "small-handwritten: 54%, 78%\n",
    "base-handwritten: 61%, 82%\n",
    "large-handwritten: 60%, 85%\n",
    "vitstr_base: icdar_EXTRACTED_train_df_vitstr_base_20250524_001621.csv\n",
    "\n",
    "cnns\n",
    "-imagenet pretrained\n",
    "resnet (standard encoding): 63%, 84%\n",
    "resnet50 (custom): 61%, 85%\n",
    "resnet50 (with pca to 384): 64%, 85%\n",
    "-text pretrained\n",
    "dresnet (resizing to 1024x1024): 63%, 84%\n",
    "crnn (on resized images): 60%, 78%\n",
    "crnn (cropping): 58%, 78%\n",
    "crnn (padding): 58%, 80%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a6eeb",
   "metadata": {},
   "source": [
    "Using gbm classifier for language identification\n",
    "small-handwritten: 77%, 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e1da8",
   "metadata": {},
   "source": [
    "I would like to compare the performance on the gender detection and language detection tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb0329",
   "metadata": {},
   "source": [
    "I would like to compare the performance you get if you use cnn_features+kaggle_features+transformer_features vs only one model features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc021808",
   "metadata": {},
   "source": [
    "# preprocessing experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30178d1a",
   "metadata": {},
   "source": [
    "I should experiment with different input formats\n",
    "1) crop wide rectangles from the images\n",
    "2) crop line/sentence \n",
    "3) crop word level\n",
    "4) crop character level\n",
    "5) use full page -> i don't need any preprocessing. Simply apply deepfeature extraction to that dataset\n",
    "6) random 32x32 crops and using them to build a single input\n",
    "7) sub character crops (-> i use info about the shape of the line)\n",
    "How much using full pages or smaller characters improves representations and so on ...\n",
    "I'll test this on the small-handwriting, on the resnet model and on the vit.\n",
    "\n",
    "how to get the crops?\n",
    "I tried with projection profiles but i have to choose good parameters cause the lines are usually curved and superimpose\n",
    "I didn't try with ccs but it may work well\n",
    "I may try using keypoints extracted with sift or others.\n",
    "I may try with ML models \n",
    "\n",
    "I'll do the following experiments:\n",
    "1) crop smaller square sections (keeping the same number of patches per writer during training)\n",
    "-> It will give useful information compared to the actual patches dataset\n",
    "(i should test on different models)\n",
    "2) crop words (or something similar to words)\n",
    "-> i can understand if having meaningful text help learning\n",
    "(I expect effects on the trocr models only)\n",
    "3) crop random wide sections (comparable to average word width)\n",
    "-> i can understand if the positive/negative effect comes from wordiness or proportion\n",
    "(i expect effects on the trocr models and on the recognition models)\n",
    "4) One dataset with more patches (eg same size of (1) but 3x more patches)\n",
    "-> will see the effect of the number of crops per writer\n",
    "5) One dataset with a big random crop from the center / paragrafi dai projection profiles / riquadro con tutto il testo dai projection profiles\n",
    "-> will see the global vs local information importance\n",
    "6) One dataset with half writers (decide the number of patches per writer from prev. experiments)\n",
    "-> to get a feeling of the impact of the number of writers on learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96f9ff",
   "metadata": {},
   "source": [
    "1) Extracting smaller patches: 1/100 of the area of the original image (icdar_train_df_patches_20250521_120324.csv)\n",
    "vit: icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250523_170002.csv\n",
    "trocr-base-handwritten: icdar_EXTRACTED_train_df_trocr-base-handwritten_20250523_173029.csv\n",
    "resnet50 (standard): icdar_EXTRACTED_train_df_resnet50_20250523_175257.csv\n",
    "2) Extracting words/sentences (icdar_train_df_words_sentences_20250522_230307.csv)\n",
    "trocr-small-stage1: icdar_EXTRACTED_train_df_trocr-small-stage1_20250523_183350.csv\n",
    "trocr-base-handwritten: icdar_EXTRACTED_train_df_trocr-base-handwritten_20250523_190523.csv\n",
    "vit: icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250523_194225.csv\n",
    "crnn: done on old\n",
    "vitstr-base: icdar_EXTRACTED_train_df_vitstr_base_20250524_004825.csv\n",
    "3) longer than higher (icdar_train_df_patches_20250522_234152.csv)\n",
    "trocr-small-stage1 icdar_EXTRACTED_train_df_trocr-small-stage1_20250523_232141.cs\n",
    "trocr-base-handwriting icdar_EXTRACTED_train_df_trocr-base-handwritten_20250523_233426.csv\n",
    "crnn icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250524_000208.csv\n",
    "4) more patches (icdar_train_df_patches_20250522_235724.csv)\n",
    "vit icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250523_203620.csv\n",
    "trocr-base-handwritten: icdar_EXTRACTED_train_df_trocr-base-handwritten_20250523_213838.csv\n",
    "resnet50: icdar_EXTRACTED_train_df_resnet50_20250523_221556.csv\n",
    "5a) full pages\n",
    "5b) crop the text region (icdar_train_df_body_20250523_181312.csv)\n",
    "vit icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250523_224422.csv\n",
    "trocr-base-handwritten icdar_EXTRACTED_train_df_trocr-base-handwritten_20250523_225140.csv\n",
    "resnet50 (standard, resizing) icdar_EXTRACTED_train_df_resnet50_20250523_230400.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356cdb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "441665b1",
   "metadata": {},
   "source": [
    "# research questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f279ea",
   "metadata": {},
   "source": [
    "## Do transformer architecture works? why? why not? how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f671fa",
   "metadata": {},
   "source": [
    "In the first experiments I cannot go above 60% accuracy with both vit and trocr\n",
    "I didn't fine tune the whole model because it is time consuming -> part of the reason could be this\n",
    "I did fine tune last transformer layers and it didn't work -> I am not sure if I've used the correct fine tuning approach. I am not sure I am using the pretrained model correctly for inference.\n",
    "I did use features extracted from the last layer -> I am not sure if i am extracting the right features (considering the pooling layer or not? considering only cls ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97579f97",
   "metadata": {},
   "source": [
    "For me is surprising that vit (general purpose) work as well as trocr -> should inquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488ee01",
   "metadata": {},
   "source": [
    "I should try using more information wrt the cls token only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153dc6c",
   "metadata": {},
   "source": [
    "I should try do a full fine tuning on a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fef56c",
   "metadata": {},
   "source": [
    "## what is the best feature extractor by default?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb58679",
   "metadata": {},
   "source": [
    "The different architectures also have a different transform/preprocessor. I saw that performance improves if I use a custom resnet transform instead of the \n",
    "standard one -> should I compare all models exploiting their own transform or the best transform for each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef99aba",
   "metadata": {},
   "source": [
    "Performance I reach wit handwriting pretrained cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef59baa",
   "metadata": {},
   "source": [
    "Performance I reach with general pretrained cnns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70addc",
   "metadata": {},
   "source": [
    "Performance I reach with handwriting pretrained transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324a7ce",
   "metadata": {},
   "source": [
    "Performance i reach with general purpose pretrained transformer models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd6769",
   "metadata": {},
   "source": [
    "I should chek wether architectures pretrained on text are better than the others if i change task (language detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588a093",
   "metadata": {},
   "source": [
    "I should split by task and compare: training on arab and classifying on arab, training on arab and classifying on english, .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286cbb4",
   "metadata": {},
   "source": [
    "I should compare the accuracy on the arab and english samples and on the same and non-same samples -> to know what bring down accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93dea0",
   "metadata": {},
   "source": [
    "## how much does contrastive pretraining help fine tuning cnns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a7a5d",
   "metadata": {},
   "source": [
    "# notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b71136",
   "metadata": {},
   "source": [
    "My research problem is: experiment with alternative ways to solve the gender detection problem\n",
    "A subproblem is: do transformer architectures work? why? why not?\n",
    "Another subproblem is: pretrained cnns work. Can I find a technique to enhance their accuracy further?\n",
    "Another subproblem is: do GNNs work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdd7a7",
   "metadata": {},
   "source": [
    "I should test seriously the contrastive approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba338cd",
   "metadata": {},
   "source": [
    "I should try determining if pooling is better than cls or if there is a superior strategy that enables to retain as much of the transformer representation as possible (eg analyzing with cnns ..) -> save a full output from the models (eg for the handwriting model) and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94c444",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "I should experiment with other models pretrained on handwriting (eg cnn pretrained on handwriting)\n",
    "layout analysis models: https://huggingface.co/microsoft/layoutlmv3-base \n",
    "text detection models: dbnet_resnet50\n",
    "scene text recognition models( cnn based): crnn, sar, vitstr\n",
    "formula recognition\n",
    "---\n",
    "to use text detection models I have to pool (since the outputs are from a fpn)-> https://chatgpt.com/share/682b4fdb-3370-8010-a3e9-d93d65bc93f5\n",
    "\n",
    "sto testando i modelli di text recognition con 3 modalità di preprocessing delel immagini -> scelgo la migliore su crnn e poi applico agli altri due la stessa\n",
    "\n",
    "I can test the models by using paddlepaddle models: https://chatgpt.com/share/682b4674-498c-8010-a9e1-c6eebf8f28c4 but it requires converting from their format\n",
    "I can test the models by using doctr -> they are already in pytorch -> should be very easy to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a45d39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "I need to change the code for evaluating the results of classifiers on top of representations because I cannot make a discussion \n",
    "based on overfitted models. \n",
    "\n",
    "I should provide both the per patch and ensemble accuracy\n",
    "\n",
    "I should evaluate both the accuracy and the roc/auc as in the icdar paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4a3a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "I have to rewrite the feature extraction code so that:\n",
    "2) I can choose the task among: writer identification, gender detection, language detection -> do writer identification \n",
    "in another file. \n",
    "I save the characteristics of the training and the resulting metrics (not the model weights) in a table format i can anlyze with csv\n",
    "I parallelize so that i can train using all my available cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb592c2",
   "metadata": {},
   "source": [
    "obiettivo: \n",
    "1) addestrare modelli che non overfittano\n",
    "provare random forests\n",
    "provare MLP con dropout\n",
    "2) accelerare l'addestramento\n",
    "parallelizzare il codice (applicando lo stesso codice a piu' files in contemporanea)\n",
    "parallelizzare il training (eg con joblib)\n",
    "utilizzare gpu per velocizzare training di MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bd23c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
