{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d553eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "source_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b250729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = source_path + \"\\\\outputs\\\\preprocessed_data\\\\\"\n",
    "LOG_FILE = output_dir+\"file_metadata_log.json\"\n",
    "file_name = \"icdar_train_df_patches_20250515_164130.csv\"\n",
    "output_file = output_dir + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15150df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_train_df_patches_20250515_164130.csv:\n",
      "full_path: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\preprocessed_data\\icdar_train_df_patches_20250515_164130.csv\n",
      "size_bytes: 862411\n",
      "created: 2025-05-15T16:41:30.197320\n",
      "modified: 2025-05-15T16:41:30.504546\n",
      "accessed: 2025-05-15T16:41:38.731775\n",
      "m patches: 5\n",
      "source_file: icdar_train_df_20250514_175905.csv\n",
      "gw: 5\n",
      "n_cc: 10\n",
      "description: For each unique index = (isEng,same_text) pair i select the m patches with more CCs\n",
      "        the final df has m*4 patches per writer, it adds the x,y,x1,y1 columns to extract the patch\n",
      "        It also add an index column that is unique for each patch\n"
     ]
    }
   ],
   "source": [
    "file_IO.read_metadata(\n",
    "    output_file,\n",
    "    log_path=LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bd3863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv:\n",
      "model: trocr-small-stage1\n",
      "description: I am performing inference with trocr-small-stage1 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-handwritten_20250516_150814.csv:\n",
      "model: trocr-small-handwritten\n",
      "description: I am performing inference with trocr-small-handwritten on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv:\n",
      "model: resnet50\n",
      "custom transform: False\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_163737.csv:\n",
      "model: resnet50\n",
      "custom transform: True\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv:\n",
      "model: vit-base-patch16-224-in21k\n",
      "custom transform: False\n",
      "description: I am performing inference with the vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv:\n",
      "model: trocr-base-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-base model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv:\n",
      "model: clip-vit-large-patch14\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the clip-vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ... I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-large-handwritten_20250517_150651.csv:\n",
      "model: trocr-large-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-large model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ..., f1024 I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for representations_trocr-small-stage1_remove head_20250517_191157.h5:\n",
      "model: trocr-small-stage1\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the trocr-small-stage1 model on the patches dataset and \n",
      "        saving the representations of all the patches in a h5 file. It serves for exploring how to best exploit the\n",
      "        extracted representations (using cls, pooling  ..)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_dresnet50_20250520_143808.csv:\n",
      "model: dresnet50\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the dbresnet model pretrained for scene text detection on the patches dataset the output is a pool of the features \n",
      "        of the deepest feature map (the model returns multiple features map since it is a feature pyramid network)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_153435.csv:\n",
      "model: crnn_vgg16_bn\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        PROBLEM: the preprocessing from nxn to 32x128 makes the image look very bad -> i should try other preprocessing approaches\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_161925.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: crop\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to 128x128 and then cropping the central region 32x128\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_165111.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: padding\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to H/3 x W and then resizing to 32x128 with padding\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vitstr_base_20250524_001621.csv:\n",
      "model: vitstr_base\n",
      "transform_mode: resize\n",
      "custom transform: False\n",
      "description: \n",
      "        testing the vitstr model with the icdar patch dataset\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_IO.show_model_instances(LOG_FILE,['model',\"transform_mode\",\"custom transform\",\"description\"], file_name)#([model_name=, custom_transform= .., ],source_file, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c58c88ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_IO.get_file_name(LOG_FILE,{'model':'trocr-small-stage1'},file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2843d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.file_IO as file_IO\n",
    "    \n",
    "    importlib.reload(file_IO)\n",
    "\n",
    "    return file_IO\n",
    "file_IO = reload_modules()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
