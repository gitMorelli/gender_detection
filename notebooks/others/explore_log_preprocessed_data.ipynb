{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d553eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "source_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(source_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b6dff",
   "metadata": {},
   "source": [
    "# preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b250729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = source_path + \"\\\\outputs\\\\preprocessed_data\\\\\"\n",
    "LOG_FILE = output_dir+\"file_metadata_log.json\"\n",
    "#file_name = \"icdar_train_df_patches_20250515_164130.csv\"\n",
    "#output_file = output_dir + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca890a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file_IO.assemble_csv_from_log(LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e681fff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['experiment', 'full_path', 'size_bytes', 'created', 'modified',\n",
       "       'accessed', 'seed', 'description', 'script_type', 'type', 'm patches',\n",
       "       'source_file', 'gw', 'n_cc', 'model', 'pooling', 'custom transform',\n",
       "       'save_h5', 'truncation', 'transform_mode', 'sort_by',\n",
       "       'n_selected_lines', 'n_slices', 'spacing', 'r_mask', 'r_min', 'prop',\n",
       "       'fraction of the max used to identify boundaries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ec90acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>full_path</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>icdar_train_df_20250514_165047.csv</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icdar_train_df_20250514_175905.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>original images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>icdar_train_df_KAGGLE_20250514_181737.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>feature extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icdar_train_df_patches_20250514_221029.csv</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>standard patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-small-stage1_20...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-small-handwritt...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>icdar_EXTRACTED_train_df_resnet50_20250516_161...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>icdar_EXTRACTED_train_df_resnet50_20250516_163...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vit-base-patch16-224-...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>icdar_EXTRACTED_train_df_clip-vit-large-patch1...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-large-handwritt...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>representations_trocr-small-stage1_remove head...</td>\n",
       "      <td>D:\\download\\PD project\\datasets\\ICDAR 2013 - G...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>icdar_EXTRACTED_train_df_dresnet50_20250520_14...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...</td>\n",
       "      <td>D:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>icdar_train_df_patches_20250521_120324.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>small_patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>icdar_train_df_words_sentences_20250522_230307...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>words-sentences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>icdar_train_df_patches_20250522_234152.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>longer-than-higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>icdar_train_df_patches_20250522_235724.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>standard patches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vit-base-patch16-224-...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>icdar_EXTRACTED_train_df_resnet50_20250523_175...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>icdar_train_df_body_20250523_181312.csv</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-small-stage1_20...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vit-base-patch16-224-...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...</td>\n",
       "      <td>d:\\burtm\\Visual_studio_code\\PD_related_project...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vit-base-patch16-224-...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>icdar_EXTRACTED_train_df_resnet50_20250523_221...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vit-base-patch16-224-...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>icdar_EXTRACTED_train_df_resnet50_20250523_230...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-small-stage1_20...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vitstr_base_20250524_...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>icdar_EXTRACTED_train_df_vitstr_base_20250524_...</td>\n",
       "      <td>c:\\Users\\andre\\VsCode\\PD related projects\\gend...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           experiment  \\\n",
       "0                  icdar_train_df_20250514_165047.csv   \n",
       "1                  icdar_train_df_20250514_175905.csv   \n",
       "2           icdar_train_df_KAGGLE_20250514_181737.csv   \n",
       "3          icdar_train_df_patches_20250514_221029.csv   \n",
       "4          icdar_train_df_patches_20250515_164130.csv   \n",
       "5   icdar_EXTRACTED_train_df_trocr-small-stage1_20...   \n",
       "6   icdar_EXTRACTED_train_df_trocr-small-handwritt...   \n",
       "7   icdar_EXTRACTED_train_df_resnet50_20250516_161...   \n",
       "8   icdar_EXTRACTED_train_df_resnet50_20250516_163...   \n",
       "9   icdar_EXTRACTED_train_df_vit-base-patch16-224-...   \n",
       "10  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "11  icdar_EXTRACTED_train_df_clip-vit-large-patch1...   \n",
       "12  icdar_EXTRACTED_train_df_trocr-large-handwritt...   \n",
       "13  representations_trocr-small-stage1_remove head...   \n",
       "14  icdar_EXTRACTED_train_df_dresnet50_20250520_14...   \n",
       "15  icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...   \n",
       "16  icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...   \n",
       "17  icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...   \n",
       "18         icdar_train_df_patches_20250521_120324.csv   \n",
       "19  icdar_train_df_words_sentences_20250522_230307...   \n",
       "20         icdar_train_df_patches_20250522_234152.csv   \n",
       "21         icdar_train_df_patches_20250522_235724.csv   \n",
       "22  icdar_EXTRACTED_train_df_vit-base-patch16-224-...   \n",
       "23  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "24  icdar_EXTRACTED_train_df_resnet50_20250523_175...   \n",
       "25            icdar_train_df_body_20250523_181312.csv   \n",
       "26  icdar_EXTRACTED_train_df_trocr-small-stage1_20...   \n",
       "27  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "28  icdar_EXTRACTED_train_df_vit-base-patch16-224-...   \n",
       "29  icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...   \n",
       "30  icdar_EXTRACTED_train_df_vit-base-patch16-224-...   \n",
       "31  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "32  icdar_EXTRACTED_train_df_resnet50_20250523_221...   \n",
       "33  icdar_EXTRACTED_train_df_vit-base-patch16-224-...   \n",
       "34  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "35  icdar_EXTRACTED_train_df_resnet50_20250523_230...   \n",
       "36  icdar_EXTRACTED_train_df_trocr-small-stage1_20...   \n",
       "37  icdar_EXTRACTED_train_df_trocr-base-handwritte...   \n",
       "38  icdar_EXTRACTED_train_df_crnn_vgg16_bn_2025052...   \n",
       "39  icdar_EXTRACTED_train_df_vitstr_base_20250524_...   \n",
       "40  icdar_EXTRACTED_train_df_vitstr_base_20250524_...   \n",
       "\n",
       "                                            full_path                type  \n",
       "0   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "1   c:\\Users\\andre\\VsCode\\PD related projects\\gend...     original images  \n",
       "2   c:\\Users\\andre\\VsCode\\PD related projects\\gend...  feature extraction  \n",
       "3   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "4   c:\\Users\\andre\\VsCode\\PD related projects\\gend...    standard patches  \n",
       "5   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "6   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "7   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "8   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "9   D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "10  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "11  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "12  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "13  D:\\download\\PD project\\datasets\\ICDAR 2013 - G...                 NaN  \n",
       "14  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "15  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "16  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "17  D:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "18  c:\\Users\\andre\\VsCode\\PD related projects\\gend...       small_patches  \n",
       "19  c:\\Users\\andre\\VsCode\\PD related projects\\gend...     words-sentences  \n",
       "20  c:\\Users\\andre\\VsCode\\PD related projects\\gend...  longer-than-higher  \n",
       "21  c:\\Users\\andre\\VsCode\\PD related projects\\gend...    standard patches  \n",
       "22  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "23  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "24  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "25  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                body  \n",
       "26  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "27  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "28  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "29  d:\\burtm\\Visual_studio_code\\PD_related_project...                 NaN  \n",
       "30  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "31  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "32  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "33  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "34  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "35  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "36  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "37  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "38  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "39  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  \n",
       "40  c:\\Users\\andre\\VsCode\\PD related projects\\gend...                 NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['experiment','full_path','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7c993d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created'] = pd.to_datetime(df['created'])\n",
    "df['experiment'] = df['experiment'].apply(lambda x: os.path.basename(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b47b1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: body\n",
      "                                 experiment  m patches\n",
      "25  icdar_train_df_body_20250523_181312.csv        1.0\n",
      "----------------------------------------\n",
      "Type: feature extraction\n",
      "                                  experiment  m patches\n",
      "2  icdar_train_df_KAGGLE_20250514_181737.csv        NaN\n",
      "----------------------------------------\n",
      "Type: longer-than-higher\n",
      "                                    experiment  m patches\n",
      "20  icdar_train_df_patches_20250522_234152.csv        5.0\n",
      "----------------------------------------\n",
      "Type: original images\n",
      "                           experiment  m patches\n",
      "1  icdar_train_df_20250514_175905.csv        NaN\n",
      "----------------------------------------\n",
      "Type: small_patches\n",
      "                                    experiment  m patches\n",
      "18  icdar_train_df_patches_20250521_120324.csv        5.0\n",
      "----------------------------------------\n",
      "Type: standard patches\n",
      "                                    experiment  m patches\n",
      "21  icdar_train_df_patches_20250522_235724.csv       15.0\n",
      "4   icdar_train_df_patches_20250515_164130.csv        5.0\n",
      "----------------------------------------\n",
      "Type: words-sentences\n",
      "                                           experiment  m patches\n",
      "19  icdar_train_df_words_sentences_20250522_230307...        9.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#show the different types of preprocessed file\n",
    "filtered = df[df['script_type'] == 'data_preprocessing']\n",
    "grouped = filtered.sort_values('created', ascending=False).groupby('type')\n",
    "for group_name, group_df in grouped:\n",
    "    print(f\"Type: {group_name}\")\n",
    "    print(group_df[['experiment', 'm patches']])\n",
    "    print('-' * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 00:16:21.468469 - icdar_EXTRACTED_train_df_vitstr_base_20250524_001621.csv - \n",
      "        testing the vitstr model with the icdar patch dataset\n",
      "2025-05-20 16:51:11.102723 - icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_165111.csv - \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to H/3 x W and then resizing to 32x128 with padding\n",
      "2025-05-20 16:19:25.051371 - icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_161925.csv - \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to 128x128 and then cropping the central region 32x128\n",
      "2025-05-20 15:34:38.476029 - icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_153435.csv - \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        PROBLEM: the preprocessing from nxn to 32x128 makes the image look very bad -> i should try other preprocessing approaches\n",
      "2025-05-20 14:38:09.230325 - icdar_EXTRACTED_train_df_dresnet50_20250520_143808.csv - \n",
      "        I am performing inference with the dbresnet model pretrained for scene text detection on the patches dataset the output is a pool of the features \n",
      "        of the deepest feature map (the model returns multiple features map since it is a feature pyramid network)\n",
      "2025-05-17 19:11:58.880979 - representations_trocr-small-stage1_remove head_20250517_191157.h5 - \n",
      "        I am performing inference with the trocr-small-stage1 model on the patches dataset and \n",
      "        saving the representations of all the patches in a h5 file. It serves for exploring how to best exploit the\n",
      "        extracted representations (using cls, pooling  ..)\n",
      "2025-05-17 17:07:53.958737 - icdar_EXTRACTED_train_df_trocr-large-handwritten_20250517_150651.csv - The model was trained on colab;\n",
      "        I am performing inference with the trocr-large model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ..., f1024 I apply the standard transform required by the model\n",
      "2025-05-17 16:44:33.205300 - icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv - The model was trained on colab;\n",
      "        I am performing inference with the clip-vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ... I apply the standard transform required by the model\n",
      "2025-05-17 16:02:48.621652 - icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv - The model was trained on colab;\n",
      "        I am performing inference with the trocr-base model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "2025-05-17 15:16:44.318702 - icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv - I am performing inference with the vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "2025-05-16 16:37:38.026354 - icdar_EXTRACTED_train_df_resnet50_20250516_163737.csv - I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "2025-05-16 16:10:22.775409 - icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv - I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "2025-05-16 15:08:14.680020 - icdar_EXTRACTED_train_df_trocr-small-handwritten_20250516_150814.csv - I am performing inference with trocr-small-handwritten on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "2025-05-16 12:25:28.589676 - icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv - I am performing inference with trocr-small-stage1 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n"
     ]
    }
   ],
   "source": [
    "# get the files created on a given source file\n",
    "source_file = 'icdar_train_df_patches_20250515_164130.csv'\n",
    "source_files=df[df['source_file'] == source_file]\n",
    "source_files = source_files.sort_values(by='created', ascending=False)\n",
    "for f in source_files[['created', 'description']].itertuples():\n",
    "    print(f\"{f.created} - {f.description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7dc6574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vitstr_base' 'crnn_vgg16_bn' 'dresnet50' 'trocr-small-stage1'\n",
      " 'trocr-large-handwritten' 'clip-vit-large-patch14'\n",
      " 'trocr-base-handwritten' 'vit-base-patch16-224-in21k' 'resnet50'\n",
      " 'trocr-small-handwritten']\n"
     ]
    }
   ],
   "source": [
    "#models used on that source file\n",
    "unique_models = source_files['model'].dropna().unique()\n",
    "print(unique_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31ac7287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_files[source_files['model']=='trocr-base-handwritten']['experiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "492bc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rows = df[df['source_file'] == 'icdar_train_df_20250514_175905.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "468e3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           experiment  \\\n",
      "3          icdar_train_df_patches_20250514_221029.csv   \n",
      "4          icdar_train_df_patches_20250515_164130.csv   \n",
      "18         icdar_train_df_patches_20250521_120324.csv   \n",
      "19  icdar_train_df_words_sentences_20250522_230307...   \n",
      "20         icdar_train_df_patches_20250522_234152.csv   \n",
      "\n",
      "                                            full_path  size_bytes  \\\n",
      "3   D:\\burtm\\Visual_studio_code\\PD_related_project...    147733.0   \n",
      "4   D:\\burtm\\Visual_studio_code\\PD_related_project...    862411.0   \n",
      "18  D:\\burtm\\Visual_studio_code\\PD_related_project...    975964.0   \n",
      "19  D:\\burtm\\Visual_studio_code\\PD_related_project...   1518303.0   \n",
      "20  D:\\burtm\\Visual_studio_code\\PD_related_project...    974807.0   \n",
      "\n",
      "                      created                    modified  \\\n",
      "3  2025-05-14 22:10:30.078981  2025-05-14T22:10:30.203676   \n",
      "4  2025-05-15 16:41:30.197320  2025-05-15T16:41:30.504546   \n",
      "18 2025-05-21 12:03:25.094240  2025-05-21T12:03:25.356208   \n",
      "19 2025-05-22 23:03:07.496495  2025-05-22T23:03:07.704174   \n",
      "20 2025-05-22 23:41:52.835060  2025-05-22T23:41:52.904894   \n",
      "\n",
      "                      accessed  seed  \\\n",
      "3   2025-05-14T22:10:30.203676   NaN   \n",
      "4   2025-05-15T16:41:38.731775   NaN   \n",
      "18  2025-05-21T12:03:25.356208   NaN   \n",
      "19  2025-05-22T23:03:07.704174   NaN   \n",
      "20  2025-05-22T23:41:52.904894   NaN   \n",
      "\n",
      "                                          description  m patches  \\\n",
      "3   For each unique index = (isEng,same_text) pair...        5.0   \n",
      "4   For each unique index = (isEng,same_text) pair...        5.0   \n",
      "18  \\n        I am reducing the dimension of the p...        5.0   \n",
      "19  \\n        I am extracting patches with words/s...        9.0   \n",
      "20  \\n        I am creating patches that are longe...        5.0   \n",
      "\n",
      "                           source_file  ...      sort_by  n_selected_lines  \\\n",
      "3   icdar_train_df_20250514_175905.csv  ...          NaN               NaN   \n",
      "4   icdar_train_df_20250514_175905.csv  ...          NaN               NaN   \n",
      "18  icdar_train_df_20250514_175905.csv  ...  black_ratio               NaN   \n",
      "19  icdar_train_df_20250514_175905.csv  ...          NaN               3.0   \n",
      "20  icdar_train_df_20250514_175905.csv  ...  black_ratio               NaN   \n",
      "\n",
      "   n_slices spacing r_mask r_min prop  \\\n",
      "3       NaN     NaN    NaN   NaN  NaN   \n",
      "4       NaN     NaN    NaN   NaN  NaN   \n",
      "18      NaN     NaN    NaN   NaN  NaN   \n",
      "19      3.0    15.0    0.1   0.5  NaN   \n",
      "20      NaN     NaN    NaN   NaN  0.2   \n",
      "\n",
      "   fraction of the max used to identify boundaries script_type  type  \n",
      "3                                              NaN         NaN   NaN  \n",
      "4                                              NaN         NaN   NaN  \n",
      "18                                             NaN         NaN   NaN  \n",
      "19                                             NaN         NaN   NaN  \n",
      "20                                             NaN         NaN   NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15150df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_train_df_patches_20250515_164130.csv:\n",
      "full_path: D:\\burtm\\Visual_studio_code\\PD_related_projects\\outputs\\preprocessed_data\\icdar_train_df_patches_20250515_164130.csv\n",
      "size_bytes: 862411\n",
      "created: 2025-05-15T16:41:30.197320\n",
      "modified: 2025-05-15T16:41:30.504546\n",
      "accessed: 2025-05-15T16:41:38.731775\n",
      "m patches: 5\n",
      "source_file: icdar_train_df_20250514_175905.csv\n",
      "gw: 5\n",
      "n_cc: 10\n",
      "description: For each unique index = (isEng,same_text) pair i select the m patches with more CCs\n",
      "        the final df has m*4 patches per writer, it adds the x,y,x1,y1 columns to extract the patch\n",
      "        It also add an index column that is unique for each patch\n"
     ]
    }
   ],
   "source": [
    "file_IO.read_metadata(\n",
    "    output_file,\n",
    "    log_path=LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bd3863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv:\n",
      "model: trocr-small-stage1\n",
      "description: I am performing inference with trocr-small-stage1 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-small-handwritten_20250516_150814.csv:\n",
      "model: trocr-small-handwritten\n",
      "description: I am performing inference with trocr-small-handwritten on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f384\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_161022.csv:\n",
      "model: resnet50\n",
      "custom transform: False\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_resnet50_20250516_163737.csv:\n",
      "model: resnet50\n",
      "custom transform: True\n",
      "description: I am performing inference with resnet50 on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f2048. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vit-base-patch16-224-in21k_20250517_151642.csv:\n",
      "model: vit-base-patch16-224-in21k\n",
      "custom transform: False\n",
      "description: I am performing inference with the vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-base-handwritten_20250517_140220.csv:\n",
      "model: trocr-base-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-base model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, .., f784. I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_clip-vit-large-patch14_20250517_144404.csv:\n",
      "model: clip-vit-large-patch14\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the clip-vit model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ... I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_trocr-large-handwritten_20250517_150651.csv:\n",
      "model: trocr-large-handwritten\n",
      "custom transform: False\n",
      "description: The model was trained on colab;\n",
      "        I am performing inference with the trocr-large model on the patches dataset and saving the output features as columns of the dataframe\n",
      "        the columns are named f1, f2, ..., f1024 I apply the standard transform required by the model\n",
      "------------------------------------------\n",
      "Metadata for representations_trocr-small-stage1_remove head_20250517_191157.h5:\n",
      "model: trocr-small-stage1\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the trocr-small-stage1 model on the patches dataset and \n",
      "        saving the representations of all the patches in a h5 file. It serves for exploring how to best exploit the\n",
      "        extracted representations (using cls, pooling  ..)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_dresnet50_20250520_143808.csv:\n",
      "model: dresnet50\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with the dbresnet model pretrained for scene text detection on the patches dataset the output is a pool of the features \n",
      "        of the deepest feature map (the model returns multiple features map since it is a feature pyramid network)\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_153435.csv:\n",
      "model: crnn_vgg16_bn\n",
      "custom transform: False\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        PROBLEM: the preprocessing from nxn to 32x128 makes the image look very bad -> i should try other preprocessing approaches\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_161925.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: crop\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to 128x128 and then cropping the central region 32x128\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_crnn_vgg16_bn_20250520_165111.csv:\n",
      "model: crnn_vgg16_bn\n",
      "transform_mode: padding\n",
      "custom transform: True\n",
      "description: \n",
      "        I am performing inference with a crnn model pretrained for handwriting recognition on the patches dataset the output is \n",
      "        a pooling of the concatenation of the output series\n",
      "        I am resizing the images to H/3 x W and then resizing to 32x128 with padding\n",
      "------------------------------------------\n",
      "Metadata for icdar_EXTRACTED_train_df_vitstr_base_20250524_001621.csv:\n",
      "model: vitstr_base\n",
      "transform_mode: resize\n",
      "custom transform: False\n",
      "description: \n",
      "        testing the vitstr model with the icdar patch dataset\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_IO.show_model_instances(LOG_FILE,['model',\"transform_mode\",\"custom transform\",\"description\"], file_name)#([model_name=, custom_transform= .., ],source_file, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c58c88ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'icdar_EXTRACTED_train_df_trocr-small-stage1_20250516_122528.csv'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_IO.get_file_name(LOG_FILE,{'model':'trocr-small-stage1'},file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7b3db",
   "metadata": {},
   "source": [
    "# feature extraction log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86690e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = source_path + \"\\\\outputs\\\\logs\\\\\"\n",
    "LOG_FILE = output_dir+\"feature_extraction_metadata_log.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file_IO.assemble_csv_from_log(LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18c3961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def summarize_cv_results(train_accs, oof_accs):\n",
    "    train_accs = np.array(train_accs)\n",
    "    oof_accs = np.array(oof_accs)\n",
    "\n",
    "    def compute_summary(arr):\n",
    "        mean = np.mean(arr)\n",
    "        variance = np.var(arr, ddof=1)  # Unbiased variance (sample variance)\n",
    "        min_val = np.min(arr)\n",
    "        max_val = np.max(arr)\n",
    "        median = np.median(arr)\n",
    "        ci_low, ci_high = st.t.interval(0.95, len(arr)-1, loc=mean, scale=st.sem(arr))\n",
    "        return mean, variance, min_val, max_val, median, (ci_low, ci_high)\n",
    "\n",
    "    train_summary = compute_summary(train_accs)\n",
    "    oof_summary = compute_summary(oof_accs)\n",
    "\n",
    "    generalization_gap = train_summary[0] - oof_summary[0]  # Difference in mean accuracies\n",
    "\n",
    "    if_name=\"IF_accuracy_\"\n",
    "    oof_name=\"OOF_accuracy_\"\n",
    "    summary = {\n",
    "            f\"{if_name}Mean\": train_summary[0],\n",
    "            f\"{if_name}Variance\": train_summary[1],\n",
    "            f\"{if_name}Min\": train_summary[2],\n",
    "            f\"{if_name}Max\": train_summary[3],\n",
    "            f\"{if_name}Median\": train_summary[4],\n",
    "            f\"{if_name}Confidence Interval\": train_summary[5],\n",
    "            f\"{oof_name}Mean\": oof_summary[0],\n",
    "            f\"{oof_name}Variance\": oof_summary[1],\n",
    "            f\"{oof_name}Min\": oof_summary[2],\n",
    "            f\"{oof_name}Max\": oof_summary[3],\n",
    "            f\"{oof_name}Median\": oof_summary[4],\n",
    "            f\"{oof_name}Confidence Interval\": oof_summary[5],\n",
    "            \"Generalization Gap\": generalization_gap\n",
    "        }\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c75cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_accuracies(df):\n",
    "    import pandas as pd\n",
    "    new_columns = []\n",
    "    for idx, row in df.iterrows():\n",
    "        c_val = row['cross_val_accuracies']\n",
    "        IF_values = c_val['IF']\n",
    "        ensembled_accuracies_IF = []\n",
    "        individual_accuracies_IF = []\n",
    "        for value in IF_values:\n",
    "            ensembled_accuracies_IF.append(value['ensembled'])\n",
    "            individual_accuracies_IF.append(value['individual'])\n",
    "        OOF_values = c_val['OOF']\n",
    "        ensembled_accuracies_OOF = []\n",
    "        individual_accuracies_OOF = []\n",
    "        for value in OOF_values:\n",
    "            ensembled_accuracies_OOF.append(value['ensembled'])\n",
    "            individual_accuracies_OOF.append(value['individual'])\n",
    "        ensembled_summary=summarize_cv_results(ensembled_accuracies_IF, ensembled_accuracies_OOF)\n",
    "        individual_summary=summarize_cv_results(individual_accuracies_IF, individual_accuracies_OOF)\n",
    "        subgroup_accuracies = row['subgroup_accuracies']\n",
    "        subgroup_ensembled_summary = {}\n",
    "        subgroup_individual_summary = {}\n",
    "        for key in subgroup_accuracies:\n",
    "            subgroup_ensembled_summary['(ensembled)'+key] = subgroup_accuracies[key]['ensembled']\n",
    "            subgroup_individual_summary['(individual)'+key] = subgroup_accuracies[key]['individual']\n",
    "        dict1 = {**ensembled_summary, **individual_summary,**subgroup_ensembled_summary, **subgroup_individual_summary}\n",
    "        new_columns.append(dict1)\n",
    "        acc_df = pd.DataFrame(new_columns)\n",
    "    return pd.concat([df.reset_index(drop=True), acc_df.reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1c2d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp=expand_accuracies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b32a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_34580\\2477984629.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df['subgroup_accuracies'][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'english+arabic,different+same': {'ensembled': 0.8368794326241135,\n",
       "  'individual': 0.7716312056737589},\n",
       " 'english,different': {'ensembled': 0.8794326241134752,\n",
       "  'individual': 0.7936170212765957},\n",
       " 'english,same': {'ensembled': 0.8333333333333334,\n",
       "  'individual': 0.7780141843971631},\n",
       " 'arabic,different': {'ensembled': 0.8404255319148937,\n",
       "  'individual': 0.7936170212765957},\n",
       " 'arabic,same': {'ensembled': 0.8466312056737588,\n",
       "  'individual': 0.7858156028368795},\n",
       " 'english,different+same': {'ensembled': 0.8466312056737588,\n",
       "  'individual': 0.7858156028368795},\n",
       " 'arabic,different+same': {'ensembled': 0.8466312056737588,\n",
       "  'individual': 0.7858156028368795},\n",
       " 'english+arabic,different': {'ensembled': 0.8466312056737588,\n",
       "  'individual': 0.7858156028368795},\n",
       " 'english+arabic,same': {'ensembled': 0.8466312056737588,\n",
       "  'individual': 0.7858156028368795}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subgroup_accuracies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6bd4791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled Summary:\n",
      "{'IF_accuracy_Mean': np.float64(0.9530226155358898), 'IF_accuracy_Variance': np.float64(0.00024046381620610927), 'IF_accuracy_Min': np.float64(0.9292035398230089), 'IF_accuracy_Max': np.float64(0.9688888888888889), 'IF_accuracy_Median': np.float64(0.9601769911504425), 'IF_accuracy_Confidence Interval': (np.float64(0.9337682613430117), np.float64(0.972276969728768)), 'OOF_accuracy_Mean': np.float64(0.6414160401002507), 'OOF_accuracy_Variance': np.float64(0.0077815151914874875), 'OOF_accuracy_Min': np.float64(0.5535714285714286), 'OOF_accuracy_Max': np.float64(0.7719298245614035), 'OOF_accuracy_Median': np.float64(0.631578947368421), 'OOF_accuracy_Confidence Interval': (np.float64(0.5318852617578234), np.float64(0.750946818442678)), 'Generalization Gap': np.float64(0.3116065754356392)}\n"
     ]
    }
   ],
   "source": [
    "expand_accuracies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7a3019",
   "metadata": {},
   "source": [
    "# exploration of feature_extraction_metadata_log.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f85f0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = source_path + \"\\\\outputs\\\\logs\\\\\"\n",
    "LOG_FILE = output_dir+\"feature_extraction_metadata_log.json\"\n",
    "df = file_IO.assemble_csv_from_log(LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aaacc117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>type of preprocessing</th>\n",
       "      <th>original raw file</th>\n",
       "      <th>input file</th>\n",
       "      <th>FE model</th>\n",
       "      <th>FE transform</th>\n",
       "      <th>classifier model</th>\n",
       "      <th>model_params</th>\n",
       "      <th>n_splits</th>\n",
       "      <th>train_on_language</th>\n",
       "      <th>...</th>\n",
       "      <th>with cross validation</th>\n",
       "      <th>with PCA</th>\n",
       "      <th>training time for cross-validation</th>\n",
       "      <th>training time for final model</th>\n",
       "      <th>cross_val_accuracies</th>\n",
       "      <th>subgroup_accuracies</th>\n",
       "      <th>is_kaggle</th>\n",
       "      <th>description</th>\n",
       "      <th>test</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250527_225518</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.972171</td>\n",
       "      <td>0.855384</td>\n",
       "      <td>{'IF': [{'ensembled': 0.9466666666666667, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250528_113837</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.999290</td>\n",
       "      <td>0.745424</td>\n",
       "      <td>{'IF': [{'ensembled': 0.9466666666666667, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250528_143032</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>dt</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9.044723</td>\n",
       "      <td>2.294748</td>\n",
       "      <td>{'IF': [{'ensembled': 0.7955555555555556, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250528_143434</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>dt</td>\n",
       "      <td>{'ccp_alpha': 0.01, 'class_weight': None, 'cri...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.561963</td>\n",
       "      <td>1.444512</td>\n",
       "      <td>{'IF': [{'ensembled': 0.5955555555555555, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250528_143602</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.235246</td>\n",
       "      <td>1.004878</td>\n",
       "      <td>{'IF': [{'ensembled': 0.9288888888888889, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20250528_143951</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.161986</td>\n",
       "      <td>1.280778</td>\n",
       "      <td>{'IF': [{'ensembled': 0.7866666666666666, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20250528_144114</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.389228</td>\n",
       "      <td>1.143128</td>\n",
       "      <td>{'IF': [{'ensembled': 0.6755555555555556, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20250528_144225</td>\n",
       "      <td>patch_dataset</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td></td>\n",
       "      <td>lgbm</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.381039</td>\n",
       "      <td>1.283346</td>\n",
       "      <td>{'IF': [{'ensembled': 0.9377777777777778, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20250528_231846</td>\n",
       "      <td>standard patches</td>\n",
       "      <td>icdar_train_df_patches_20250515_164130.csv</td>\n",
       "      <td>icdar_EXTRACTED_train_df_trocr-base-handwritte...</td>\n",
       "      <td>trocr-base-handwritten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>logreg</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.302375</td>\n",
       "      <td>1.113176</td>\n",
       "      <td>{'IF': [{'ensembled': 0.7866666666666666, 'ind...</td>\n",
       "      <td>{'english+arabic,different+same': {'ensembled'...</td>\n",
       "      <td>False</td>\n",
       "      <td>I am training a classifier on the feature vec...</td>\n",
       "      <td>this is a test column</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment type of preprocessing  \\\n",
       "0  20250527_225518         patch_dataset   \n",
       "1  20250528_113837         patch_dataset   \n",
       "2  20250528_143032         patch_dataset   \n",
       "3  20250528_143434         patch_dataset   \n",
       "4  20250528_143602         patch_dataset   \n",
       "5  20250528_143951         patch_dataset   \n",
       "6  20250528_144114         patch_dataset   \n",
       "7  20250528_144225         patch_dataset   \n",
       "8  20250528_231846      standard patches   \n",
       "\n",
       "                            original raw file  \\\n",
       "0  icdar_train_df_patches_20250515_164130.csv   \n",
       "1  icdar_train_df_patches_20250515_164130.csv   \n",
       "2  icdar_train_df_patches_20250515_164130.csv   \n",
       "3  icdar_train_df_patches_20250515_164130.csv   \n",
       "4  icdar_train_df_patches_20250515_164130.csv   \n",
       "5  icdar_train_df_patches_20250515_164130.csv   \n",
       "6  icdar_train_df_patches_20250515_164130.csv   \n",
       "7  icdar_train_df_patches_20250515_164130.csv   \n",
       "8  icdar_train_df_patches_20250515_164130.csv   \n",
       "\n",
       "                                          input file                FE model  \\\n",
       "0  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "1  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "2  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "3  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "4  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "5  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "6  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "7  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "8  icdar_EXTRACTED_train_df_trocr-base-handwritte...  trocr-base-handwritten   \n",
       "\n",
       "  FE transform classifier model  \\\n",
       "0                          lgbm   \n",
       "1                          lgbm   \n",
       "2                            dt   \n",
       "3                            dt   \n",
       "4                        logreg   \n",
       "5                        logreg   \n",
       "6                        logreg   \n",
       "7                          lgbm   \n",
       "8          NaN           logreg   \n",
       "\n",
       "                                        model_params  n_splits  \\\n",
       "0  {'boosting_type': 'gbdt', 'class_weight': None...         5   \n",
       "1  {'boosting_type': 'gbdt', 'class_weight': None...         5   \n",
       "2  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         5   \n",
       "3  {'ccp_alpha': 0.01, 'class_weight': None, 'cri...         5   \n",
       "4  {'C': 1.0, 'class_weight': None, 'dual': False...         5   \n",
       "5  {'C': 1.0, 'class_weight': None, 'dual': False...         5   \n",
       "6  {'C': 1.0, 'class_weight': None, 'dual': False...         5   \n",
       "7  {'boosting_type': 'gbdt', 'class_weight': None...         5   \n",
       "8  {'C': 1.0, 'class_weight': None, 'dual': False...         5   \n",
       "\n",
       "  train_on_language  ... with cross validation with PCA  \\\n",
       "0               all  ...                  True    False   \n",
       "1               all  ...                  True    False   \n",
       "2               all  ...                  True    False   \n",
       "3               all  ...                  True    False   \n",
       "4               all  ...                  True    False   \n",
       "5               all  ...                  True     True   \n",
       "6               all  ...                  True     True   \n",
       "7               all  ...                  True     True   \n",
       "8               all  ...                  True     True   \n",
       "\n",
       "   training time for cross-validation  training time for final model  \\\n",
       "0                            3.972171                       0.855384   \n",
       "1                            3.999290                       0.745424   \n",
       "2                            9.044723                       2.294748   \n",
       "3                            5.561963                       1.444512   \n",
       "4                            4.235246                       1.004878   \n",
       "5                            6.161986                       1.280778   \n",
       "6                            6.389228                       1.143128   \n",
       "7                            3.381039                       1.283346   \n",
       "8                            5.302375                       1.113176   \n",
       "\n",
       "                                cross_val_accuracies  \\\n",
       "0  {'IF': [{'ensembled': 0.9466666666666667, 'ind...   \n",
       "1  {'IF': [{'ensembled': 0.9466666666666667, 'ind...   \n",
       "2  {'IF': [{'ensembled': 0.7955555555555556, 'ind...   \n",
       "3  {'IF': [{'ensembled': 0.5955555555555555, 'ind...   \n",
       "4  {'IF': [{'ensembled': 0.9288888888888889, 'ind...   \n",
       "5  {'IF': [{'ensembled': 0.7866666666666666, 'ind...   \n",
       "6  {'IF': [{'ensembled': 0.6755555555555556, 'ind...   \n",
       "7  {'IF': [{'ensembled': 0.9377777777777778, 'ind...   \n",
       "8  {'IF': [{'ensembled': 0.7866666666666666, 'ind...   \n",
       "\n",
       "                                 subgroup_accuracies is_kaggle  \\\n",
       "0  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "1  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "2  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "3  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "4  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "5  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "6  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "7  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "8  {'english+arabic,different+same': {'ensembled'...     False   \n",
       "\n",
       "                                         description                   test  \\\n",
       "0   I am training a classifier on the feature vec...                    NaN   \n",
       "1   I am training a classifier on the feature vec...  this is a test column   \n",
       "2   I am training a classifier on the feature vec...  this is a test column   \n",
       "3   I am training a classifier on the feature vec...  this is a test column   \n",
       "4   I am training a classifier on the feature vec...  this is a test column   \n",
       "5   I am training a classifier on the feature vec...  this is a test column   \n",
       "6   I am training a classifier on the feature vec...  this is a test column   \n",
       "7   I am training a classifier on the feature vec...  this is a test column   \n",
       "8   I am training a classifier on the feature vec...  this is a test column   \n",
       "\n",
       "  n_components  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8         0.95  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db5ae795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp=file_IO.expand_accuracies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b6c1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_exp[(df_exp['type of preprocessing'] == 'patch_dataset') & (df_exp['FE model'] == 'trocr-base-handwritten')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba196112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cross_val_accuracies', 'subgroup_accuracies', 'IF_accuracy_Mean', 'IF_accuracy_Variance', 'IF_accuracy_Min', 'IF_accuracy_Max', 'IF_accuracy_Median', 'IF_accuracy_Confidence Interval', 'OOF_accuracy_Mean', 'OOF_accuracy_Variance', 'OOF_accuracy_Min', 'OOF_accuracy_Max', 'OOF_accuracy_Median', 'OOF_accuracy_Confidence Interval']\n"
     ]
    }
   ],
   "source": [
    "print([col for col in filtered_df.columns if 'acc' in col.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7341a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>IF_accuracy_Mean</th>\n",
       "      <th>IF_accuracy_Variance</th>\n",
       "      <th>OOF_accuracy_Mean</th>\n",
       "      <th>OOF_accuracy_Variance</th>\n",
       "      <th>Generalization Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250527_225518</td>\n",
       "      <td>0.815074</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.587368</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.227706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250528_113837</td>\n",
       "      <td>0.815074</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.587368</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.227706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment  IF_accuracy_Mean  IF_accuracy_Variance  OOF_accuracy_Mean  \\\n",
       "0  20250527_225518          0.815074              0.000053           0.587368   \n",
       "1  20250528_113837          0.815074              0.000053           0.587368   \n",
       "\n",
       "   OOF_accuracy_Variance  Generalization Gap  \n",
       "0               0.001329            0.227706  \n",
       "1               0.001329            0.227706  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df[['experiment', 'IF_accuracy_Mean','IF_accuracy_Variance','OOF_accuracy_Mean','OOF_accuracy_Variance','Generalization Gap']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ffe2b",
   "metadata": {},
   "source": [
    "# modify files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29c0bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = source_path + \"\\\\outputs\\\\preprocessed_data\\\\\"\n",
    "LOG_FILE = output_dir+\"file_metadata_log.json\"\n",
    "file_name = \"icdar_train_df_20250514_175905.csv\"\n",
    "output_file = output_dir + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "493b0f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for icdar_train_df_body_20250523_181312.csv:\n",
      "full_path: c:\\Users\\andre\\VsCode\\PD related projects\\gender_detection\\outputs\\preprocessed_data\\icdar_train_df_body_20250523_181312.csv\n",
      "size_bytes: 161795\n",
      "created: 2025-05-23T18:13:12.353873\n",
      "modified: 2025-05-23T18:13:12.357975\n",
      "accessed: 2025-05-23T18:13:12.357975\n",
      "m patches: 1\n",
      "source_file: icdar_train_df_20250514_175905.csv\n",
      "fraction of the max used to identify boundaries: 0.1\n",
      "description: \n",
      "        I crop each image so that there is no white around the text -> i am zooming on the text\n"
     ]
    }
   ],
   "source": [
    "file_IO.read_metadata(\n",
    "    output_file,\n",
    "    log_path=LOG_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fc7e84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated log for icdar_train_df_20250514_175905.csv\n"
     ]
    }
   ],
   "source": [
    "file_IO.add_or_update_file(\n",
    "    output_file, LOG_FILE,\n",
    "    custom_metadata={\n",
    "        \"script_type\": \"data_preprocessing\",\n",
    "        \"type\": \"original images\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27f4ce",
   "metadata": {},
   "source": [
    "# easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2843d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_modules():\n",
    "    import importlib\n",
    "    import utils.file_IO as file_IO\n",
    "    \n",
    "    importlib.reload(file_IO)\n",
    "\n",
    "    return file_IO\n",
    "file_IO = reload_modules()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneralPurposeML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
